{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/yeabinmoon/Documents/ibs_course/Summer2023/BUS243/PS/PS3/sample.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['stars','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant good service!!\n",
      "I like food!!\n",
      "This product good!!\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "print(remove_stopwords(\"Restaurant had a really good service!!\"))\n",
    "print(remove_stopwords(\"I did not like the food!!\"))\n",
    "print(remove_stopwords(\"This product is not good!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in df['text']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6155264</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Totally love this place. While growing up in D...</td>\n",
       "      <td>[totally, love, this, place, while, growing, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030548</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Their lunch bento is usually a great deal, as ...</td>\n",
       "      <td>[their, lunch, bento, is, usually, great, deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553207</th>\n",
       "      <td>5.0</td>\n",
       "      <td>On a road trip across the country and had to s...</td>\n",
       "      <td>[on, road, trip, across, the, country, and, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630933</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Came here for my Birthday dinner and was kind ...</td>\n",
       "      <td>[came, here, for, my, birthday, dinner, and, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254822</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Better than most diners. Looks like it was rec...</td>\n",
       "      <td>[better, than, most, diners, looks, like, it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351460</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Peanut butter filled chocolate covered banana!...</td>\n",
       "      <td>[peanut, butter, filled, chocolate, covered, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353921</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great cause, great prices, great products. St ...</td>\n",
       "      <td>[great, cause, great, prices, great, products,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814228</th>\n",
       "      <td>5.0</td>\n",
       "      <td>My Frigidaire upright freeze would not go belo...</td>\n",
       "      <td>[my, frigidaire, upright, freeze, would, not, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263630</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Really enjoyed this Zionsville gem! Great seaf...</td>\n",
       "      <td>[really, enjoyed, this, zionsville, gem, great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164678</th>\n",
       "      <td>1.0</td>\n",
       "      <td>christ just avoid eating here lmao. It's so gr...</td>\n",
       "      <td>[christ, just, avoid, eating, here, lmao, it, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stars                                               text  \\\n",
       "6155264    5.0  Totally love this place. While growing up in D...   \n",
       "3030548    4.0  Their lunch bento is usually a great deal, as ...   \n",
       "6553207    5.0  On a road trip across the country and had to s...   \n",
       "4630933    1.0  Came here for my Birthday dinner and was kind ...   \n",
       "3254822    4.0  Better than most diners. Looks like it was rec...   \n",
       "...        ...                                                ...   \n",
       "4351460    5.0  Peanut butter filled chocolate covered banana!...   \n",
       "1353921    5.0  Great cause, great prices, great products. St ...   \n",
       "4814228    5.0  My Frigidaire upright freeze would not go belo...   \n",
       "3263630    5.0  Really enjoyed this Zionsville gem! Great seaf...   \n",
       "3164678    1.0  christ just avoid eating here lmao. It's so gr...   \n",
       "\n",
       "                                            tokenized_text  \n",
       "6155264  [totally, love, this, place, while, growing, u...  \n",
       "3030548  [their, lunch, bento, is, usually, great, deal...  \n",
       "6553207  [on, road, trip, across, the, country, and, ha...  \n",
       "4630933  [came, here, for, my, birthday, dinner, and, w...  \n",
       "3254822  [better, than, most, diners, looks, like, it, ...  \n",
       "...                                                    ...  \n",
       "4351460  [peanut, butter, filled, chocolate, covered, b...  \n",
       "1353921  [great, cause, great, prices, great, products,...  \n",
       "4814228  [my, frigidaire, upright, freeze, would, not, ...  \n",
       "3263630  [really, enjoyed, this, zionsville, gem, great...  \n",
       "3164678  [christ, just, avoid, eating, here, lmao, it, ...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6155264</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Totally love this place. While growing up in D...</td>\n",
       "      <td>[totally, love, this, place, while, growing, u...</td>\n",
       "      <td>[total, love, thi, place, while, grow, up, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030548</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Their lunch bento is usually a great deal, as ...</td>\n",
       "      <td>[their, lunch, bento, is, usually, great, deal...</td>\n",
       "      <td>[their, lunch, bento, is, usual, great, deal, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553207</th>\n",
       "      <td>5.0</td>\n",
       "      <td>On a road trip across the country and had to s...</td>\n",
       "      <td>[on, road, trip, across, the, country, and, ha...</td>\n",
       "      <td>[on, road, trip, across, the, countri, and, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630933</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Came here for my Birthday dinner and was kind ...</td>\n",
       "      <td>[came, here, for, my, birthday, dinner, and, w...</td>\n",
       "      <td>[came, here, for, my, birthdai, dinner, and, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254822</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Better than most diners. Looks like it was rec...</td>\n",
       "      <td>[better, than, most, diners, looks, like, it, ...</td>\n",
       "      <td>[better, than, most, diner, look, like, it, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351460</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Peanut butter filled chocolate covered banana!...</td>\n",
       "      <td>[peanut, butter, filled, chocolate, covered, b...</td>\n",
       "      <td>[peanut, butter, fill, chocol, cover, banana, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353921</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great cause, great prices, great products. St ...</td>\n",
       "      <td>[great, cause, great, prices, great, products,...</td>\n",
       "      <td>[great, caus, great, price, great, product, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814228</th>\n",
       "      <td>5.0</td>\n",
       "      <td>My Frigidaire upright freeze would not go belo...</td>\n",
       "      <td>[my, frigidaire, upright, freeze, would, not, ...</td>\n",
       "      <td>[my, frigidair, upright, freez, would, not, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263630</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Really enjoyed this Zionsville gem! Great seaf...</td>\n",
       "      <td>[really, enjoyed, this, zionsville, gem, great...</td>\n",
       "      <td>[realli, enjoi, thi, zionsvil, gem, great, sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164678</th>\n",
       "      <td>1.0</td>\n",
       "      <td>christ just avoid eating here lmao. It's so gr...</td>\n",
       "      <td>[christ, just, avoid, eating, here, lmao, it, ...</td>\n",
       "      <td>[christ, just, avoid, eat, here, lmao, it, so,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stars                                               text  \\\n",
       "6155264    5.0  Totally love this place. While growing up in D...   \n",
       "3030548    4.0  Their lunch bento is usually a great deal, as ...   \n",
       "6553207    5.0  On a road trip across the country and had to s...   \n",
       "4630933    1.0  Came here for my Birthday dinner and was kind ...   \n",
       "3254822    4.0  Better than most diners. Looks like it was rec...   \n",
       "...        ...                                                ...   \n",
       "4351460    5.0  Peanut butter filled chocolate covered banana!...   \n",
       "1353921    5.0  Great cause, great prices, great products. St ...   \n",
       "4814228    5.0  My Frigidaire upright freeze would not go belo...   \n",
       "3263630    5.0  Really enjoyed this Zionsville gem! Great seaf...   \n",
       "3164678    1.0  christ just avoid eating here lmao. It's so gr...   \n",
       "\n",
       "                                            tokenized_text  \\\n",
       "6155264  [totally, love, this, place, while, growing, u...   \n",
       "3030548  [their, lunch, bento, is, usually, great, deal...   \n",
       "6553207  [on, road, trip, across, the, country, and, ha...   \n",
       "4630933  [came, here, for, my, birthday, dinner, and, w...   \n",
       "3254822  [better, than, most, diners, looks, like, it, ...   \n",
       "...                                                    ...   \n",
       "4351460  [peanut, butter, filled, chocolate, covered, b...   \n",
       "1353921  [great, cause, great, prices, great, products,...   \n",
       "4814228  [my, frigidaire, upright, freeze, would, not, ...   \n",
       "3263630  [really, enjoyed, this, zionsville, gem, great...   \n",
       "3164678  [christ, just, avoid, eating, here, lmao, it, ...   \n",
       "\n",
       "                                            stemmed_tokens  \n",
       "6155264  [total, love, thi, place, while, grow, up, in,...  \n",
       "3030548  [their, lunch, bento, is, usual, great, deal, ...  \n",
       "6553207  [on, road, trip, across, the, countri, and, ha...  \n",
       "4630933  [came, here, for, my, birthdai, dinner, and, w...  \n",
       "3254822  [better, than, most, diner, look, like, it, wa...  \n",
       "...                                                    ...  \n",
       "4351460  [peanut, butter, fill, chocol, cover, banana, ...  \n",
       "1353921  [great, caus, great, price, great, product, st...  \n",
       "4814228  [my, frigidair, upright, freez, would, not, go...  \n",
       "3263630  [realli, enjoi, thi, zionsvil, gem, great, sea...  \n",
       "3164678  [christ, just, avoid, eat, here, lmao, it, so,...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df['tokenized_text'] ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(df.stemmed_tokens, \n",
    "                 min_count=2,\n",
    "                 window=5,\n",
    "                 vector_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amaz', 0.9993680715560913),\n",
       " ('delici', 0.9993669986724854),\n",
       " ('great', 0.9993337988853455),\n",
       " ('nice', 0.9993144273757935),\n",
       " ('staff', 0.9992288947105408),\n",
       " ('veri', 0.9991763830184937),\n",
       " ('friendli', 0.9990977644920349),\n",
       " ('food', 0.9990846514701843),\n",
       " ('atmospher', 0.9990285038948059),\n",
       " ('servic', 0.9990248680114746)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = model.wv['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,-1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for i in df.iloc[0,-1][1:]:\n",
    "    try:\n",
    "        temp2 = model.wv[i]\n",
    "        temp = temp+temp2\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  31.322147  ,  -39.609703  ,  -15.14511   ,  -16.449615  ,\n",
       "         -7.0398088 ,  -20.34108   ,   -2.64317   ,   65.874504  ,\n",
       "        -32.190628  ,   12.507106  ,   36.91133   ,   -2.0329497 ,\n",
       "        -62.02079   ,   55.615513  ,  -45.05184   ,   12.463446  ,\n",
       "         48.507244  ,   -5.4311814 ,   -8.73776   ,   13.00371   ,\n",
       "        -50.40148   ,  -16.123743  ,   40.41085   ,   40.845287  ,\n",
       "         25.74981   ,    9.821339  ,  -67.70664   ,  -26.69522   ,\n",
       "        -18.21294   ,  -34.317444  ,   -8.476881  ,   14.390266  ,\n",
       "        -25.38965   ,  -30.399046  ,  -33.39265   ,    5.813058  ,\n",
       "         93.62835   ,   -4.7510047 ,   10.273965  ,  -55.636883  ,\n",
       "         17.300093  ,   13.424539  ,  -26.742598  ,  -36.518112  ,\n",
       "         53.54179   ,   -7.7364287 ,  -17.264534  ,   -4.115738  ,\n",
       "         34.176125  ,   32.1474    ,   -7.8522396 ,    4.564003  ,\n",
       "        -25.315678  ,    5.58418   ,   16.304407  ,    4.369137  ,\n",
       "         21.514114  ,   24.883797  ,   28.176983  ,    0.4843203 ,\n",
       "         -0.24421552,  -61.166653  ,  -13.551972  ,  -22.6986    ,\n",
       "         22.29455   ,  -28.433304  ,  -19.19346   ,  -78.92323   ,\n",
       "       -100.01965   ,  -62.417877  ,   30.902807  ,   22.908607  ,\n",
       "         11.67842   ,  -64.70222   ,    7.0995164 ,  -19.00066   ,\n",
       "         -9.625323  ,   -0.44717872,  -39.821995  ,   35.991165  ,\n",
       "         10.056063  ,  -40.597717  ,  -24.24034   ,  114.886055  ,\n",
       "        -15.061266  ,   43.44342   ,   19.108503  ,   14.607164  ,\n",
       "         58.9291    ,  -32.05319   ,   34.603394  ,  -57.513565  ,\n",
       "         31.96545   ,    2.278928  ,   55.783405  ,   -6.288941  ,\n",
       "         27.646055  ,  -33.85067   ,    6.0216994 ,   73.35307   ,\n",
       "          5.962262  ,   15.338821  ,   84.18876   ,   15.429764  ,\n",
       "        -36.969154  ,  -73.25954   ,   39.51377   ,   40.546337  ,\n",
       "       -112.74713   ,  -43.601936  ,  -18.691935  ,  -22.084045  ,\n",
       "         56.931976  ,  -47.059113  ,  -60.39954   ,    7.3986363 ,\n",
       "         54.16647   ,   50.21098   ,  -36.610695  ,  -33.263855  ,\n",
       "        -19.354687  ,   20.079826  ,   33.773544  ,  -24.58821   ,\n",
       "         30.680445  ,   56.719     ,   20.595871  ,  -10.844056  ,\n",
       "        -54.24218   ,   36.665905  ,   58.16289   ,   49.714024  ,\n",
       "          0.76714617,  -39.17309   ,    8.040832  ,   37.61668   ,\n",
       "        -61.87737   ,   -7.426941  ,  -20.82685   ,  -16.26764   ,\n",
       "         35.960316  ,    9.978579  ,   22.326845  ,   46.408916  ,\n",
       "         96.09576   ,    8.45734   ,  -54.923195  ,  -54.76231   ,\n",
       "         44.770687  ,  -64.83902   ], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
