{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Qf0ezwRsughh"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from math import log\n",
        "import os\n",
        "\n",
        "from typing import Iterable, Tuple, Dict\n",
        "\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk import FreqDist\n",
        "\n",
        "kUNK = \"<UNK>\"\n",
        "\n",
        "def log10(x):\n",
        "    return log(x) / log(10)\n",
        "\n",
        "def lower(str):\n",
        "    return str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TfIdf:\n",
        "    \"\"\"Class that builds a vocabulary and then computes tf-idf scores\n",
        "    given a corpus.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size=10000,\n",
        "                 tokenize_function=TreebankWordTokenizer().tokenize,\n",
        "                 normalize_function=lower, unk_cutoff=2):\n",
        "        self._vocab_size = vocab_size\n",
        "        self._total_docs = 0\n",
        "\n",
        "        self._vocab_final = False\n",
        "        self._vocab = {}\n",
        "        self._unk_cutoff = unk_cutoff\n",
        "\n",
        "        self._tokenizer = tokenize_function\n",
        "        self._normalizer = normalize_function\n",
        "\n",
        "        # Add your code here!\n",
        "        ##############################\n",
        "        # code 1\n",
        "        self._training = {}\n",
        "        self._document = []\n",
        "        ##############################\n",
        "\n",
        "\n",
        "\n",
        "    def train_seen(self, word: str, count: int=1):\n",
        "        \"\"\"Tells the language model that a word has been seen @count times.  This\n",
        "        will be used to build the final vocabulary.\n",
        "\n",
        "        word -- The string represenation of the word.  After we\n",
        "        finalize the vocabulary, we'll be able to create more\n",
        "        efficient integer representations, but we can't do that just\n",
        "        yet.\n",
        "\n",
        "        count -- How many times we've seen this word (by default, this is one).\n",
        "        \"\"\"\n",
        "\n",
        "        assert not self._vocab_final, \\\n",
        "            \"Trying to add new words to finalized vocab\"\n",
        "\n",
        "        # Add your code here!\n",
        "        ##############################\n",
        "        # code 2\n",
        "        if word in self._training:\n",
        "          self._training[word] += count\n",
        "        else:\n",
        "          self._training[word] = count\n",
        "        ##############################\n",
        "\n",
        "\n",
        "    def add_document(self, text: str):\n",
        "        \"\"\"\n",
        "        Tokenize a piece of text and add the entries to the class's counts.\n",
        "\n",
        "        text -- The raw string containing a document\n",
        "        \"\"\"\n",
        "\n",
        "        assert self._vocab_final, \"add_document can only be run with finalized vocab\"\n",
        "        \n",
        "        temp = []\n",
        "        for word in self.tokenize(text):\n",
        "            temp.append(word)\n",
        "        self._document.append(temp)\n",
        "\n",
        "    def tokenize(self, sent: str) -> Iterable[int]:\n",
        "        \"\"\"Return a generator over tokens in the sentence; return the vocab\n",
        "        of a sentence if finalized, otherwise just return the raw string.\n",
        "\n",
        "        sent -- A string\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # You don't need to modify this code.\n",
        "        for ii in self._tokenizer(sent):\n",
        "            if self._vocab_final:\n",
        "                yield self.vocab_lookup(ii)\n",
        "            else:\n",
        "                yield ii\n",
        "\n",
        "    def doc_tfidf(self, doc: str) -> Dict[Tuple[str, int], float]:\n",
        "        \"\"\"Given a document, create a dictionary representation of its tfidf vector\n",
        "\n",
        "        doc -- raw string of the document\"\"\"\n",
        "\n",
        "        counts = FreqDist(self.tokenize(doc))\n",
        "        d = {}\n",
        "        for ii in self._tokenizer(doc):\n",
        "            ww = self.vocab_lookup(ii)\n",
        "            d[(ww, ii)] = counts.freq(ww) * self.inv_docfreq(ww)\n",
        "        return d\n",
        "                \n",
        "    def term_freq(self, word: int) -> float:\n",
        "        \"\"\"Return the frequence of a word if it's in the vocabulary, zero otherwise.\n",
        "\n",
        "        word -- The integer lookup of the word.\n",
        "        \"\"\"\n",
        "\n",
        "        return 0.0\n",
        "\n",
        "    def inv_docfreq(self, word: int) -> float:\n",
        "        \"\"\"Compute the inverse document frequency of a word.  Return 0.0 if\n",
        "        the word index is outside of our vocabulary (however, this should \n",
        "        never happen in normal operation).\n",
        "\n",
        "        Keyword arguments:\n",
        "        word -- The word to look up the document frequency of a word.\n",
        "\n",
        "        \"\"\"\n",
        "        self._total_docs = len(self._document)\n",
        "        count_ = 0\n",
        "        for itr in self._document:\n",
        "          if word in itr:\n",
        "            count_ += 1\n",
        "        if count_ == 0:\n",
        "          return 0.0\n",
        "        else:\n",
        "          return log10(self._total_docs/count_)\n",
        "\n",
        "    def vocab_lookup(self, word: str) -> int:\n",
        "        \"\"\"\n",
        "        Given a word, provides a vocabulary integer representation.  Words under the\n",
        "        cutoff threshold shold have the same value.  All words with counts\n",
        "        greater than or equal to the cutoff should be unique and consistent.\n",
        "\n",
        "        This is useful for turning words into features in later homeworks.\n",
        "\n",
        "        word -- The word to lookup\n",
        "        \"\"\"\n",
        "        assert self._vocab_final, \\\n",
        "            \"Vocab must be finalized before looking up words\"\n",
        "\n",
        "        if word in self._vocab:\n",
        "            return self._vocab[word]\n",
        "        else:\n",
        "            return self._vocab[kUNK]\n",
        "\n",
        "    def finalize(self):\n",
        "        \"\"\"\n",
        "        Fixes the vocabulary as static, prevents keeping additional vocab from\n",
        "        being added\n",
        "        \"\"\"\n",
        "\n",
        "        # Add code to generate the vocabulary that the vocab lookup function can use!\n",
        "\n",
        "        #######################################################################################\n",
        "        # code 3\n",
        "        temp = {key for key, value in self._training.items() if value > self._unk_cutoff}\n",
        "        self._vocab = {key: str(i + 1) for i, key in enumerate(temp)}\n",
        "        self._vocab[kUNK] = '0'\n",
        "\n",
        "        self._vocab_final = True\n",
        "        #######################################################################################\n",
        "\n"
      ],
      "metadata": {
        "id": "SI_hSuwWupfw"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unk_cutoff = 2\n",
        "vocab = TfIdf(unk_cutoff = unk_cutoff)"
      ],
      "metadata": {
        "id": "_-1z509ZDE2X"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.train_seen(\"a\", 300)\n",
        "vocab.train_seen(\"b\", 100)\n",
        "vocab.finalize()"
      ],
      "metadata": {
        "id": "HHjVmrWcDJF4"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab._vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnJaOqJ-DSlp",
        "outputId": "57ed5851-b5d5-473f-e508-43d7c84a04be"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': '1', 'b': '2', '<UNK>': '0'}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab._training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GvEx_WTDVWF",
        "outputId": "1c8d805a-dc4e-4887-d184-2231c3abd5c6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 300, 'b': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.add_document('a a b')\n",
        "vocab.add_document('b b c')\n",
        "vocab.add_document('a a a')\n",
        "vocab.add_document('a a a')"
      ],
      "metadata": {
        "id": "49fFtsD1GEc5"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab._document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr0pHheTEME5",
        "outputId": "b1e1f897-011f-4e2b-a767-29110d3bea94"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_a = vocab.vocab_lookup(\"a\")\n",
        "word_b = vocab.vocab_lookup(\"b\")\n",
        "word_c = vocab.vocab_lookup(\"c\")\n",
        "word_d = vocab.vocab_lookup(\"d\")"
      ],
      "metadata": {
        "id": "0D20ZuwlFLbY"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.inv_docfreq(word_d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJNU9daVHR72",
        "outputId": "014bb4e6-f4cd-412d-c019-e0b050b56f9f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log10(1.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ29WQ3LFbWy",
        "outputId": "1bc31326-0062-4243-cfe1-a01832f2f42c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11394335230683676"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'1' in FreqDist(vocab._document[0]).keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A3jyYnnFdIN",
        "outputId": "669c23be-08f0-4236-9828-c1da5573003a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab._document[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUFXStGuHTvg",
        "outputId": "d7376c7e-b39a-4dcf-e7fd-b187308dad50"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.doc_tfidf('a a b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWA1DHr5HhRe",
        "outputId": "2505a717-17c3-4bab-a7ea-63179b237e75"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('1', 'a'): 0.8888888888888888, ('2', 'b'): 0.6666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.doc_tfidf('a a c')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5lm0FDrK6Y9",
        "outputId": "1993bdba-dac5-4eb6-ab53-9988bc09505b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('1', 'a'): 0.08329249107219994, ('0', 'c'): 0.20068666377598743}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.doc_tfidf('a a a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjPQuVy0LN1k",
        "outputId": "b7bf5cf6-1aaf-42ec-b9bf-630fa9888f85"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('1', 'a'): 0.1249387366082999}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QpQWKv6eLSLc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}