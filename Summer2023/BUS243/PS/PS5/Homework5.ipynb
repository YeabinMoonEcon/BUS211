{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, I recommend utilizing **Google Colab**; however, you also have the option to submit the Jupyter Notebook. Prior to submission, please ensure that you have verified the proper execution of all code segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall delve into the Yelp data to enhance our comprehension of it. Our objective involves training a deep neural network sentiment classifier.\n",
    "\n",
    "First, download the JSON Data from the following link: https://www.yelp.com/dataset/download. The total file size is approximately 9 GB, thus ensure your local machine has sufficient storage capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect `yelp_academic_dataset_review.json` data. Use the following below. Note that We only need `stars` and `text` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_large_json_to_dataframe(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line)\n",
    "            data.append(json_obj)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**. What is the number of observations present in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. Let's do simple data mining. \n",
    "\n",
    "- Employ the `sample()` method on the Pandas dataframe to extract a random 1 percent sample of observations. Then, save the extracted sample to a variable named `df`. Also, extract a random 1,000 sample and save it to a variable name `test_df`.\n",
    "- Convert the `stars` values into binary format, assigning a value of one if the rating is greater than or equal to 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Learn a word embedding while fitting a neural net classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to learn a word embedding, it is essential to estimate the vocabulary size for the entire population data. However, it is unlikely to see the population data. Even JSON data youâ€™ve downloaded is a sample. Here,  we need to estimate it using `df` dataframe.\n",
    "\n",
    "Let's figure out the size of vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simply the process:\n",
    "\n",
    "1. Convert all words to lowercase after tokenization.\n",
    "2. Eliminate stop words and punctuation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** What is the number of tokens in `df`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** What is the number of distinct tokens in in `df`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go back to Heaps' law we learned in lecture 2:\n",
    "$$M=kT^b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** Explain the Heaps' law in words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see: $$\\log M =\\log k + b \\log T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**. Estimate $k$ and $b$ using linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Supply your understanding of using Heap's law ($k$ and $b$) to approximate the vocabulary size for the complete population dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's learn a word embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `input_dim`: set the size of the vocabulary you found in **Q4**.\n",
    "- `output_dim`: set 50.\n",
    "- `input_length`: use the length of the longest content in the `text` column of `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** Train the model using `model.add(tf.keras.layers.Dense(1, activation='sigmoid'))` in the last layer. Try to achieve the highest possible levle of accuracy (at least **95% training accuracy**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.** Evaluate the model with `test_df` using accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run `tf.keras.backend.clear_session()` to clear all sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Use Pre-Trained GloVe Embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** Train and evaluate the model.\n",
    "\n",
    "- Use `glove.6B.50d.txt`\n",
    "- Try to get the accuracy as high as possible.\n",
    "- Evaluate the model with `test_df` using accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** Provide your intuitive assessment of the advantages and disadvantages associated with both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
