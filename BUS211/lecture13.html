<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>BUS211:lecture13</title>

		<link rel="stylesheet" href="../dist/reset.css">
		<link rel="stylesheet" href="../dist/reveal.css">
		<link rel="stylesheet" href="../dist/theme/black.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="../plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					<textarea data-template>
						## Lecture 13
						### BUS 211A-3<br>
					
					</textarea>
				  </section>

				<section>
					<h4>Update: GROUP project</h4>
					
				<ul>
					<li class="fragment">Submit the outline of the project by Thursday 12 pm</li>
					<ul>
					<li class="fragment">What is your specific area of interest? </li>
					<li class="fragment">Why is it more important than other areas?</li>
					<li class="fragment">Why is the cell phone tracking data fit for your interest? </li>
					<li class="fragment">One page outline, no coding is necessary</li>
					<li class="fragment">Give you a feedback</li>
					</ul>
				</ul>
					</section>


					<section>
				<ul>
					<li class="fragment">Submit the initial report by November 4th</li>
					<ul>
					<li class="fragment">Need to adress:</li>
					<ul>
					<li class="fragment">Previous motivations</li>
					<li class="fragment">Feedback</li>
					<li class="fragment">What is the main challenge in answering the questions? </li>
					<li class="fragment">To answer the question, how do you manipulate/refine data, verbally?</li>
				</ul>
					<li class="fragment">11 font size, 3 page double-space report</li>
					</ul>
				</ul>
		</section>

		<section>
				Schedule meetings on November 21th—25th to discuss your progress during office hours or zoom
	</section>
				
				
				<section>
					<h4>SRS revisit</h4>
					<ul>

						<li class="fragment">Think about players in basketball play in different positions on the court</li>
						<li class="fragment">Points, assists may depend on their position</li>
						<li class="fragment">If we perform simple random sampling, there's a chance that some categories won't be included in our sample</li>
						<li class="fragment">Revisit WNBA 2016-2017 season data</li>
						<li class="fragment">We might want to analyze the patterns for each individual position</li>
						<ul><li class="fragment">there are five unique positions in our dataset</li></ul>
					</ul>
				</section>
				
				<section>
					<ul>
						<li class="fragment">The downside of simple random sampling is that it can leave out individuals playing in a certain position on the field</li>

					</ul>
					
					<img src="pics/lecture13_1.png" class="fragment" width = 500> 
					<ul>
						<li class="fragment">To ensure we end up with a sample that has observations for all the categories of interest, we can change the sampling method</li>

					</ul>
				</section>
				<section>
					<ul>
						<li class="fragment">We can organize our dataset into different groups, and then do simple random sampling for every group</li>

					</ul>
					
					<img src="pics/lecture13_2.png" class="fragment" width = 500> 
					<ul>
						<li class="fragment">This sampling method is called <b>stratified sampling</b> </li>
						<li class="fragment">Each individual stratified group is also known as a <b>stratum</b>, and multiple groups are known as <b>strata</b></li>

					</ul>
				</section>

				<section>
					<h4>Simple Random Sampling</h4>
					<pre data-id="code-animation" class="fragment"><code class="hljs" data-trim data-line-numbers>
						library(dplyr)
						set.seed(1)
						wnba_sampled <-  sample_n(wnba, size = 10)
						head(wnba_sampled)
						</code></pre>	
					
					<ul>
						<li class="fragment">When we print the first six rows of the dataframe, we can see that all variables from the wnba dataframe are preserved</li>
						<li class="fragment">When we estimate the average total points scored for this 10-player sample, we get these results:</li>

					</ul>
					<pre data-id="code-animation" class="fragment"><code class="hljs" data-trim data-line-numbers>
						mean(wnba_sampled$PTS)
						</code></pre>	
					
				</section>


				<section>
					<h4>Stratified Sampling</h4>
					<ul>
						<li class="fragment">When data is split with the group_by() function, this effectively creates strata</li>
						<li class="fragment">Once the data is split, we can apply one or more functions to each strata</li>

					</ul>
					<pre data-id="code-animation" class="fragment"><code class="hljs" data-trim data-line-numbers>
						set.seed(1)
						wnba %>% 
  							# Split: stratify by player position
  							group_by(Pos) %>% 
  							# Apply: sample 10 observations for each player position stratum
  							sample_n(10) %>%
  							# Apply & combine: calculate average points scored for each stratum, combine results
  							summarize(mean_pts = mean(PTS))
						</code></pre>	
					</section>
				<section>
						<pre data-id="code-animation" class="fragment"><code class="hljs" data-trim data-line-numbers>
							# A tibble: 5 × 2
							Pos   mean_pts
							<chr>    <dbl>
						  1 C         182.
						  2 F         185.
						  3 F/C       190.
						  4 G         184.
						  5 G/F       198.
							</code></pre>	

							<ul>
								<li class="fragment">The problem is that the number of total points is influenced by the number of games played</li>
								<pre data-id="code-animation" class="fragment"><code class="hljs" data-trim data-line-numbers>
								min(wnba$Games_Played)
								[1] 2
								man(wnba$Games_Played)
								[1] 32
								</code></pre>	
		
							</ul>
				</section>
				<section>
					<pre data-id="code-animation" class="fragment"><code class="hljs" data-trim data-line-numbers>
						wnba %>% 
  							mutate(games_stratum = cut(Games_Played, breaks = 3)) %>%
  							group_by(games_stratum) %>% 
  							summarize(n = n()) %>% 
  							mutate(percentage = n / sum(n) * 100) %>% 
  							arrange(desc(percentage))
						</code></pre>	

						
							<pre data-id="code-animation" class="fragment"><code class="hljs" data-trim data-line-numbers>
							# A tibble: 3 × 3
								games_stratum     n percentage
								<fct>         <int>      <dbl>
							1 (22,32]         104      72.7 
							2 (12,22]          26      18.2 
							3 (1.97,12]        13       9.09
							</code></pre>	
						<ul>
							<li class="fragment">Now we notice the potential problem of SRS when calculating statistsic</li>
							<li class="fragment">How do we handle it?</li>
						</ul>
				</section>

				<section>
					<ul>
						<li class="fragment">One solution to this problem is to use stratified sampling while being mindful of the proportions in the population</li>
						<li class="fragment">We can stratify our dataset by the number of games played, and then sample randomly from each stratum a proportional number of observations</li>
					</ul>
					<img src="pics/lecture13_3.png" class="fragment" width = 500> 
				</section>

				<section>
					<img src="pics/lecture13_4.png" class="fragment" width = 380> 
					<img src="pics/lecture13_5.png" class="fragment" width = 380> 
					<ul>
						<li class="fragment">The variability of the sampling was quite large, and many sample means were unrepresentative, being far from the population mean</li>
						<li class="fragment">In fact, this sampling method doesn't seem to perform better than simple random sampling</li>
					</ul>
				</section>

				<section>
					<ul>
						<li class="fragment">Because of the choice of strata</li>
						<ul>
						<li class="fragment">stratified the data by the number of games played</li>
						</ul>
						<li class="fragment">It makes more sense to stratify the data by number of minutes played, rather than by number of games played</li>
						<li class="fragment">Here are a few guidelines for choosing good strata:</li>
						<ul>
						<li class="fragment">minimize the variability within each stratum</li>
						<li class="fragment">maximize the variability between strata</li>
						<li class="fragment">the stratification criterion should be strongly correlated with the property you're trying to measure</li>
						</ul>
						
						
					</ul>
				</section>

				<section>
					<h4>Side note</h4>
					<ul>
						<li class="fragment">We have been working with the sample_n() function from dplyr in this lesson because it returns randomly sampled rows from a dataframe</li>
						<li class="fragment">The dplyr package also offers the sample_frac() function that returns a dataframe of randomly sampled rows</li>
					</ul>
					<pre data-id="code-animation" class="fragment"><code class="hljs" data-trim data-line-numbers>
						over_22 <- wnba %>% 
  							filter(Games_Played > 22) %>% 
  							sample_frac(0.25)
						</code></pre>	
				</section>


				<section>
					<h4>Measuring Variability</h4>
					<ul>
						<li class="fragment">Variance: look at average squared deviations from the mean</li>
						<ul>
						<li class="fragment">positive and negative gaps get equal weight</li>
						</ul>
						<li class="fragment">Notation 1</li>
						<ul>
							<li class="fragment">random variable: $Y_i$</li>
							<li class="fragment">Expectation: $E[Y_i]$, formal notions of probability</li>
							<ul>
								<li class="fragment">a weighted average of all possible values that $Y_i$ can take on</li>
								<li class="fragment">what's a weight?</li>
							</ul>
							</ul>
					</ul>
				</section>
				<section>
										<ul>
						<li class="fragment">For a given population</li>
						<ul>
							<li class="fragment">there is only one $E[Y_i]$, while there are many $\bar{Y}$, depending on how we choose $n$</li>
							<li class="fragment">$E[Y_i]$ called a <b>parameter</b></li>
							<li class="fragment">LLN tells that in large samples, the sample avearge is likely to be very close to the corresponding population mean</li>
							</ul>
							
							
					</ul>
				</section>

				<section>
					<ul>
						<li class="fragment">The sample variance of $Y_i$ in a sample size $n$ is defined as $S(Y_i)^2 = \frac{1}{n}\sum_{i=1}^{n}(Y_i-\bar{Y})^2$</li>
						<li class="fragment">The corresponding population variance replaces averages with expectations, giving: <br>$V(Y_i) = E[(Y_i-E[Y_i])^2]$</li>
						<li class="fragment">Like $E[Y_i]$, the quantity $V(Y_i)$ is a fixed feature of a population: a parameter</li>
						<ul>
							<li class="fragment">$V(Y_i)=\sigma_Y^2$</li>
						</ul>
					</ul>
				</section>

				<section>
					<ul>
						<li class="fragment">Because variances square the data, it can be very large</li>
						<li class="fragment">Use the square root of the variance: <b>standard deviation</b>, $\sigma_Y$</li>
						<li class="fragment">Suppose we are interested in quantifying the variance of the sample mean in repeated samples</li>
						<ul>
							<li class="fragment">$V(\bar{Y})=E[(\bar{Y}-E[\bar{Y}])^2] = E[(\bar{Y}-E[Y_i])^2]$</li>
						</ul>
						<li class="fragment">Note that $V(Y_i)$ is different from $V(\bar{Y})$</li>
					</ul>
				</section>
				<section>
					<ul>
						<li class="fragment">We write $V(\bar{Y})$ for the variance of the sample mean, while $V(Y_i)$ denotes the variance of the underlying data</li>
						<li class="fragment">$V(\bar{Y})$ is called sampling variance</li>
						<li class="fragment">$V(\bar{Y})$ is related to descriptive variance, but sit is etermined by sample size. </li>
						<ul>
							<li class="fragment">$V(\bar{Y})=V([\frac{1}{n}\sum_{i=1}^{n}Y_i])$</li>
						</ul>
						<li class="fragment">Assuming: independent and identically distributed random samples</li>
						<ul>
							<li class="fragment">$V(\bar{Y})=\frac{1}{n^2}\sum_{i=1}^{n}\sigma_Y^2=\frac{\sigma_Y^2}{n}$</li>
						</ul>
					</ul>
				</section>

				<section>
					<ul>
						<li class="fragment">$V(\bar{Y})=\frac{\sigma_Y^2}{n}$</li>
						<li class="fragment">More data means less dispersion of sample avareges in repeated samples</li>
						<li class="fragment">When the sample size is very large, there's almost no dispersion at all </li>
						<ul>
							<li class="fragment">LLN at work</li>
						</ul>
						<li class="fragment">In practice, often work with the standard deviation of the sample mean, called standard error</li>
						<ul>
							<li class="fragment">$SE(\bar{Y}) = \frac{\sigma_Y}{\sqrt{n}}$</li>
						</ul>
					</ul>
				</section>

				<section>
					<ul>
						<li class="fragment">Most population quantities are unknown and must be estimated</li>
						<li class="fragment">When quantifying the sampling variance of a sample mean, we work with an <b>estimated standard error</b></li>
	
						<ul>
							<li class="fragment">$\hat{SE(\bar{Y})} = \frac{S(Y_i)}{\sqrt{n}}$</li>
						</ul>
						<li class="fragment">Having laid out a simple scheme to measure variability using standard erros, it remains to interpret this measure</li>
					</ul>
				</section>

				<section>
					<h4>t-Statistic and the Central Limit Theorem</h4>
					<ul>
						<li class="fragment">Suppose the data at hand come from a distribution for which we believe $E[Y_i]$ takes $\mu$</li>
						<ul>
							<li class="fragment">called a working <b>hypothesis</b>, or the null hypothesis as a reference point</li>
						</ul>
						<li class="fragment">A t-statistic for the sample mean under the hypothesis is consutrcted as</li>
						<ul>
							<li class="fragment">$t(\mu)=\frac{\bar{Y}-\mu}{\hat{SE}(\bar{Y})}$</li>
							<li class="fragment">When $\mu=0$, the t-statistic is the ratio of the sample mean to its estimated standard error</li>
						</ul>
					</ul>
				</section>
				<section>
					
					<ul>
						
						<li class="fragment">If $E[Y_i]=\mu$, the quantity $t(\mu)$ has as a sampling distribution that is very close to a bell-shaped standard normal distribution</li>
						<ul>
							<li class="fragment">called <b>the Central Limit Theorem</b></li>
						</ul>
					</ul>
						<img src="pics/lecture13_6.png" class="fragment" width = 380> 
						<img src="pics/lecture13_7.png" class="fragment" width = 380>
					
				</section>

				<section>
					
					<ul>
						
						<li class="fragment">For the standard normal distribution: </li>
						<ul>
							<li class="fragment">values large than $\pm 2$ are highly unlikely</li>
							<li class="fragment">less than 5% of the time</li>
						</ul>
						<li class="fragment">Customary to judge any t-stat larger than about 2 as too unlikely to be consistent with the null</li>
						<li class="fragment">When the null is 0, and the t-stat exceeds 2 in absolute value, the sample mean is <b>significantly different from zero</b></li>
						<li class="fragment">We can construct the set of all values of $\mu$ consistent with the data</li>
						<ul>
							<li class="fragment">confidence interval for $E[Y_i]$</li>
							<li class="fragment"> $[\bar{Y}-2\times \hat{SE}(\bar{Y}),\bar{Y}+2\times \hat{SE}(\bar{Y})]$</li>
						</ul>
					</ul>
						
				</section>
				<section>
					<h3>Data Preparation</h3>
					There is a collection of standard data preparation algorithms that can be applied to structured data
				</section>
				<section>
					<ul>
						<li class="fragment">Techniques such as data cleaning can identify and fix errors in data like missing values</li>
						<li class="fragment">Data transforms can change the sacle, type, and probability distribution of variables in the dataset</li>
						<li class="fragment">Techniques such as feature selection and dimensionality reduction can reduce the number of input variables</li>
						
					</ul>
				</section>
				<section>
					<h4>We are going to learn</h4>
					<ol>
						<li class="fragment">Data Cleaning</li>
						<ul>
							<li class="fragment">identify and correct mistakes or erros in the data</li>
						</ul>
						<li class="fragment">Feature Selection</li>
						<ul>
							<li class="fragment">identify those input variables that are most relevant to the task</li>
						</ul>
						<li class="fragment">Data Transforms</li>
						<ul>
							<li class="fragment">change the scale or distribution of variables</li>
						</ul>
						<li class="fragment">Feature Engineering</li>
						<ul>
							<li class="fragment">derive new variables from available data</li>
						</ul>
						<li class="fragment">Dimensionality Reduction</li>
						<ul>
							<li class="fragment">create compact projections of the data</li>
						</ul>
					</ol>
				</section>
			</div>

		<script src="../dist/reveal.js"></script>
		<script src="../plugin/notes/notes.js"></script>
		<script src="../plugin/markdown/markdown.js"></script>
		<script src="../plugin/highlight/highlight.js"></script>
		<script src="../plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				progress: false,
				touch: true,
				slideNumber: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});
		</script>
	</body>
</html>
