---
title: "report"
author: "li.zhou"
date: "2022-11-12"
output: html_document
---

```{r}
library("readr")
library("dplyr")
Places <- read_csv('/Users/lizhou/Desktop/brandeis/22fall/data foundation/safegraph_data_purchase_sep-10-2022/your_data_sep_10_2022_1152pm.csv.gz')
Patterns <- read_csv('/Users/lizhou/Desktop/brandeis/22fall/data foundation/homework2/safegraph_data_purchase_sep-19-2022/your_data_sep_19_2022_0557pm.csv.gz')
df <- left_join(Patterns, Places, by = "placekey")
head(df)
```


```{r}
# the number of na in naics column in places dataset
nacount <- Places[is.na(Places$naics_code),]
nacount

# the number of na in naics column in df
nacount2 <- df[is.na(df$naics_code),]
nacount2

```



```{r}
df_filter<- subset(df, naics_code==722513)
head(df_filter)
count<-df_filter %>% group_by(location_name.x)%>%count()%>%arrange(n)
count
lessthan10 <-count %>% filter(n<10)
lessthan10
tentotwenty <-count %>% filter(n>=10 & n<20)
tentotwenty
twentytothirty <-count %>% filter(n>=20 & n<30)
twentytothirty
thirtytoforty <-count %>% filter(n>=30 & n<40)
thirtytoforty
fortytofifty <-count %>% filter(n>=40 & n<50)
fortytofifty
fiftytosixty <-count %>% filter(n>=50 & n<60)
fiftytosixty
sixtytoseventy <-count %>% filter(n>=60 & n<=70)
sixtytoseventy
```


#### The naics code for fast food restaurant is 722513. But pattern dataset do not have the naics code column, so we left join the pattern with places and filter the row whose naics code is 722513. We select 2228 rows whose naics code is 722513. And we want to see the distribution of these restaurant(how many times they occurs). So we use group_by function and count function. As the result shows, we totally filter 248 restaurants. 

#### disadvantages: one of the most disadvantages of this method is that : Because the primary key of the pattern and places dataset can not be fully corresponded to, in the time of left join lost a lot of data: we can see that the number of na in places is 10, but the number of na in df became 688, which indicates that the placekey does not fully correspond.

#### advantages: The most significant advantage of this method is that the naics code is classified in a very strict and standardized way, and there are naics that correspond directly to fast food restaurants, so the results can be obtained more accurately.

### And we want to see the summary of these row visit number to identify whether the results of this method makes sense.

```{r}
# sum the number of visits to different branches of the same brand
df_filter_sum <- df_filter %>% group_by(location_name.x) %>% summarise(sum=sum(raw_visit_counts)) %>% arrange(sum)
df_filter_sum
```

```{r}
# see the statistical feature of the raw visit number
summary(df_filter_sum)

# 3rd Qu.is 1495.0 , so we identify the restaurants whose raw visit number greater than 1500 as first group.
firstgroup <- subset(df_filter_sum, sum>1500)
firstgroup

# 1st Qu. is 252.0, so we identify the restaurants whose raw visit number greater than 252 and less than 3000 as second group.
secondgroup <- subset(df_filter_sum, sum>252 & sum <=3000)
secondgroup

# we identify the restaurants whose raw visit number less than 252 as third group.
thirdgroup <- subset(df_filter_sum, sum<252)
thirdgroup

# detail about Clover Food Lab and Black Seed Cafe & Grill
Clover <- subset(df_filter, location_name.x == "Clover Food Lab")
Clover
Black <- subset(df_filter, location_name.x == "Black Seed Cafe & Grill")
Black


# why group by with such method? We want to divide the restaurant brand into 3 groups by their popularity, which can be helpful for afterward analytics.
```

#### We find some intersting facts after we divide the three groups. In group 1, There seems to be two outliers here: Clover Food Lab（the sum is 279345）;Black Seed Cafe & Grill(the sum is 298609	).They were a bit too big compared to the rest of the first group, so we looked at the details through the filter function



# The Boston area issued a policy on the regulation of masks in April and again in June：In the policy released in April, it was mentioned masks are no longer required on public transportation including on the MBTA (except on The Ride), commuter rail, buses, ferries, and airplanes, or while in rideshares (Uber and Lyft), taxis, and livery vehicles. Face coverings are also no longer required inside or outside of transportation hubs, including train stations, bus stops, and airports.（https://www.mass.gov/info-details/covid-19-travel）In the policy released in June, the new guidance advises that masks indoors are optional for most individuals, regardless of vaccination status. (https://www.mass.gov/news/massachusetts-department-of-public-health-releases-updated-mask-advisory)

# We want to divide the month as (1-3;4-6;7-8) and then draw a line graph of the top ten most representative restaurant brands in each of the three groups in terms of the number of visits per month.
```{r}

tail(firstgroup,17)
tail(secondgroup,11)
tail(thirdgroup,18)
```


```{r}
df_use <- select(df_filter, placekey,location_name.x,street_address.x,date_range_start,raw_visit_counts)

subset(df_use, location_name.x == "Tatte Bakery & Cafe")
# select address: 369 Huntington Ave

subset(df_use, location_name.x == "B.GOOD")
# select address: 359 Huntington Ave

subset(df_use, location_name.x == "Tasty Burger")
# select address: 1301 Boylston St

subset(df_use, location_name.x == "McDonald's")
# select address: 870 Massachusetts Ave

subset(df_use, location_name.x == "Einstein Brothers")
# select address: 725 Commonwealth Ave

subset(df_use, location_name.x == "Breadwinners")
# select address: 595 Commonwealth Ave Fl 2

subset(df_use, location_name.x == "Subway")
# select address: 	700 Commonwealth Avenue Boston University & 700 Commonwealth Ave

subset(df_use, location_name.x == 'Qdoba Mexican Grill')
# select address: 393 Huntington Ave Ste 101

subset(df_use, location_name.x == 'Boloco')
# select address: 283 Longwood Ave

subset(df_use, location_name.x == 'Dudley Cafe')
# select address: 15 Warren St


```

```{r}
library(lubridate)
library(timechange)
group1_test <- subset(df_use,  street_address.x== '369 Huntington Ave'| street_address.x == '359 Huntington Ave' | street_address.x == '1301 Boylston St' |street_address.x == '870 Massachusetts Ave'| street_address.x == '725 Commonwealth Ave'| street_address.x == '595 Commonwealth Ave Fl 2'| street_address.x == '700 Commonwealth Avenue Boston University'|street_address.x == '700 Commonwealth Ave'| street_address.x == '393 Huntington Ave Ste 101'|street_address.x == '283 Longwood Ave' | street_address.x == '15 Warren St')
group1_test$date_range_start <- month(group1_test$date_range_start)
group1_test
```


```{r}
subset(df_use, location_name.x == "Hot Pot Buffet")
# select address: 70 Beach St

subset(df_use, location_name.x == "Fins Sushi and Grill")
# select address: 240 Cambridge St	

subset(df_use, location_name.x == "Anna's Taqueria")
# select address: 242 Cambridge St	

subset(df_use, location_name.x == "La Colombe")
# select address: 745 Atlantic Ave	

subset(df_use, location_name.x == "Burger King")
# select address: 1 Maverick Sq

subset(df_use, location_name.x == "Five Guys")
# select address: 1223 Commonwealth Ave

subset(df_use, location_name.x == "Dig Inn")
# select address: 557 Boylston St

subset(df_use, location_name.x == "The Capital Burger")
# select address:	159 Newbury St

subset(df_use, location_name.x == "Wingstop")
# select address:	173 Border St

subset(df_use, location_name.x == "Burro Bar South End")
# select address: 1357 Washington St


## Restaurants in this group usually have 2-3 branches
```


```{r}
group2_test <- subset(df_use,  street_address.x== '70 Beach St'| street_address.x == '240 Cambridge St' | street_address.x == '242 Cambridge St' |street_address.x == '745 Atlantic Ave'| street_address.x == '1 Maverick Sq'| street_address.x == '1223 Commonwealth Ave'| street_address.x == '557 Boylston St'|street_address.x == '159 Newbury St'| street_address.x == '173 Border St'|street_address.x == '1357 Washington St')
group2_test$date_range_start <- month(group2_test$date_range_start)
group2_test
```


```{r}
subset(df_use, location_name.x == "Soup Shack")
# select address: 779 Centre St

subset(df_use, location_name.x == "Scali Cafe")
# select address: 147 Pearl St (use name Scali Cafe)
# because there are more than one restaurant in this address

subset(df_use, location_name.x == "Sushi Kappo")
# select address: 86 Peterborough St

subset(df_use, location_name.x == "D'Angelo Grilled Sandwiches")
# select address: 700 Atlantic Ave.

subset(df_use, location_name.x == "Poke Station and Kitchen")
# select address: 313 Huntington Ave

subset(df_use, location_name.x == "Samira's Homemade")
# select address: 468 Harrison Ave

subset(df_use, location_name.x == "Chutney's")
# select address: 350 Longwood Ave
# use name to subset because there are more than one restaurant in this address

subset(df_use, location_name.x == "Baking with Joy")
# select address: 100 Hanover St
# use name to subset because there are more than one restaurant in this address

subset(df_use, location_name.x == "TreMonte Restaurant & Bar North End")
# select address: 76 Salem St

subset(df_use, location_name.x == "Kwench Juice Cafe")
# select address: 230 Congress St

## After manual selection, we found that removing the restaurants with missing data, the top ten restaurants in group3 all have only one outlet, so we decided to use loctaion name to subset.

```


```{r}
group3_test <- subset(df_use,  location_name.x== 'Soup Shack'| location_name.x =="Scali Cafe" | location_name.x ==  "Sushi Kappo"|location_name.x == "D'Angelo Grilled Sandwiches"| location_name.x == "Poke Station and Kitchen"| location_name.x == "Samira's Homemade"| location_name.x == "Chutney's"|location_name.x == "Baking with Joy"| location_name.x == "TreMonte Restaurant & Bar North End"|location_name.x == "Kwench Juice Cafe")
group3_test$date_range_start <- month(group3_test$date_range_start)
group3_test

```

```{r}
library(tidyverse)
b <- subset(df_use, location_name.x == "B.GOOD")
b %>% group_by(street_address.x) %>% count()
```

```{r}
subset(df_use, location_name.x == "McDonald's") %>% group_by()


```