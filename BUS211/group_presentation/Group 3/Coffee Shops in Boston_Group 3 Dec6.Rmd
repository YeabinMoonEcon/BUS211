---
title: "Coffee Shops in Boston and Inflation"
author: "Group 3"
date: "2022-12-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(RSQLite)
library(dplyr)
library(tidyverse)
library(DBI)
library(ggplot2)
```

```{r}
### There are two databases, place, and pattern, which have detailed information about locations in the Boston area. By filtering out all the coffee shops in the Boston area, we can get a lot of information about coffee shops, including location and number of visits. We are removing repeated columns to avoid contaminating the dataset. Through the analysis of these data, we hope to be able to test the hypothesis: "Inflation is causing more people to go to the top 3 major brands than to independent coffee shops."

places <- read_csv('your_data_sep_14_2022_0335pm_pla.csv')
patterns <- read_csv('your_data_sep_23_2022_0506pm_pat.csv')

df <- patterns %>%
  left_join(places[-c(2:5,11:14)], by = "placekey")

```

```{r}
### We can first filter the dataset through either the naic codes 722515, 722513,and 722511 or through the top_category of Restaurants and Other Eating Places. Both options contain information about coffee shops and generate the same results. However, these results include other types of businesses besides coffee shops.

newnaics_df <- df %>%
  filter(grepl('722515|722513', naics_code))

newnaics_df

```

```{r}
### Identifying missing values in our dataset. There is around 2% of missing values in the column category_tags. To filter by "Coffee_Shops" under the category_tags column, we decided to drop the rows with missing values because they represent a small portion in our dataset (2%).  

na_sum <-colSums(is.na(newnaics_df))

print(na_sum)

na_values <- newnaics_df %>% is.na() %>% colSums()

na_counts_pct <- na_values * 100 / nrow(newnaics_df)

na_df <- data.frame(na_c = na_values, na_pct = na_counts_pct )

na_df <- data.frame(t(na_df))

print(na_df)

na_df_category <- na_df %>% 
    select(ends_with("_tags"))

print(na_df_category)

```

```{r}
### To narrow our dataset to only coffee shops, we will used the following strategy.

### Total of number of visits per store location
coffee_df <- newnaics_df %>%
  filter(grepl('Coffee Shop', category_tags)) %>%
  select(location_name, postal_code, street_address,raw_visit_counts,date_range_start,raw_visitor_counts,naics_code)%>%
  group_by(location_name, street_address,postal_code,naics_code) %>%
  summarise(total_visits=sum(raw_visit_counts),total_visitors=sum(raw_visitor_counts), n()) %>%arrange(desc(total_visits))

names(coffee_df)[7]<-"months"

coffee_df

### Remove stores with less than a total of 1000 visits and less than 8 months
target_visits0 <-  coffee_df %>%
  filter(total_visits > 400)%>%
  filter(months>=8)

target_visits0 

```

```{r}
### We reviewed the 722513 naics, and we found that only the "Jugos Supremo" should be removed (based on the definition of coffee shop)
check_naics<- target_visits0%>%
  group_by(naics_code)%>%
  count()
check_naics

### Removed "Jugos Supremo"
target_visits<- target_visits0%>%
  filter(location_name!="Jugos Supremo")
target_visits

```


```{r}
### Top and bottom 10 coffee shops for the 8-month period. We also did some reach of top ten stores to see their location and environment on Google map.
top_10 <- target_visits %>%
  head(10)

top_10

bottom_10 <- target_visits %>%
  arrange(total_visits) %>%
  head(10)

bottom_10 

```

```{r}
### To show how many franchises and independent stores in our dataset
check_franchises<- coffee_df%>%
  group_by(location_name)%>%
  count()
names(check_franchises)[2]<-"shop_number"
check_franchises

franchises<- filter(check_franchises, shop_number>1)%>%
  arrange(desc(shop_number))
franchises

indepentent<-check_franchises%>%
  filter(shop_number==1)
indepentent

```

```{r}
### To see the repeat consumers
visit_visitor <- target_visits %>%
  ungroup()%>%
  mutate(relation=total_visits/total_visitors)%>%
  arrange(desc(total_visits))

##From here, we can see that the more coffee a coffee shop sells, the more likely it is to have repeat customers
##there is a exception called "Longfellow Cafe". It ranks 11 but has high percentage of repeat customers. We did some research and found that it is in BU, so the main customers are students of BU, which makes it reasonable to have high percentage of repeat customers.

visit_visitor_1<- visit_visitor%>%
  select(location_name,total_visits,total_visitors,relation)

visit_visitor_1

```

```{r}
### To calculate the total number of visits per zip_code
postal_visit <- target_visits%>%
  group_by(postal_code)%>%
  summarise(visits_by_postal=sum(total_visits))%>%
  arrange(desc(visits_by_postal))
postal_visit

### To calculate the total number of coffee shops per zip code
total_coffee_shops <- target_visits %>%
  group_by(postal_code)%>%
  summarise(total_coffee_shops_per_zipcode = n())%>%
  arrange(desc(total_coffee_shops_per_zipcode))
total_coffee_shops

### Creating a dataframe with postal_visit and total_coffee_shops
new_df_for_ratio <- left_join(postal_visit, total_coffee_shops, by = "postal_code")

### Calculating the Ratio
new_df_for_ratio%>%
  mutate(average_visits = (visits_by_postal/total_coffee_shops_per_zipcode))%>%
  arrange(desc(average_visits))

```

```{r}
### We need to clean up the monthly data as well, so that we can analyze it by month.
monthly_df <- filter(newnaics_df, street_address %in% target_visits$street_address)

monthly_df

```

```{r}
### Top and bottom 10 coffee shops per month
Jan_top10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-01-01') %>%
  arrange(desc(raw_visit_counts)) %>%
  head(10)

Jan_top10

Jan_bottom10 <-monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-01-01') %>%
  arrange(raw_visit_counts) %>%
  head(10)

Jan_bottom10

Feb_top10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-02-01') %>%
  arrange(desc(raw_visit_counts)) %>%
  head(10)

Feb_top10

Feb_bottom10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-02-01') %>%
  arrange(raw_visit_counts) %>%
  head(10)

Feb_bottom10

Mar_top10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-03-01') %>%
  arrange(desc(raw_visit_counts)) %>%
  head(10)

Mar_top10

Mar_bottom10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-03-01') %>%
  arrange(raw_visit_counts) %>%
  head(10)

Mar_bottom10

Apr_top10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-04-01') %>%
  arrange(desc(raw_visit_counts)) %>%
  head(10)

Apr_top10

Apr_bottom10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-04-01') %>%
  arrange(raw_visit_counts) %>%
  head(10)

Apr_bottom10

May_top10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-05-01') %>%
  arrange(desc(raw_visit_counts)) %>%
  head(10)

May_top10

May_bottom10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-05-01') %>%
  arrange(raw_visit_counts) %>%
  head(10)

May_bottom10

Jun_top10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-06-01') %>%
  arrange(desc(raw_visit_counts)) %>%
  head(10)

Jun_top10

Jun_bottom10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-06-01') %>%
  arrange(raw_visit_counts) %>%
  head(10)

Jun_bottom10

Jul_top10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-07-01') %>%
  arrange(desc(raw_visit_counts)) %>%
  head(10)

Jul_top10

Jul_bottom10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-07-01') %>%
  arrange(raw_visit_counts) %>%
  head(10)

Jul_bottom10

Aug_top10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-08-01') %>%
  arrange(desc(raw_visit_counts)) %>%
  head(10)

Aug_top10

Aug_bottom10 <- monthly_df %>%
  filter(grepl('Coffee Shop', category_tags) & date_range_start == '2022-08-01') %>%
  arrange(raw_visit_counts) %>%
  head(10)

Aug_bottom10

```

```{r}
### Since Dunkinâ€™ is one of the most affordable options, its sales might be affected during inflation, so we analyzed it to see if there is a trend for coffee consumption and inflation.

dunk<-data.frame(inflation_rate=c(3,5,3,4,4,3,3,3),
                      Month=c("January", "February", "March", "April", "May", "June", "July", "August"))
all(dunk$Month %in% month.name)
dunk$Month <- factor(dunk$Month, levels=month.name)
```

```{r}
ggplot(data=dunk, aes(x=Month,y=inflation_rate, group=1)) +
  geom_line()+
  geom_point()

```

```{r}
###To show number of total visits per month
monthly<-aggregate(cbind(raw_visit_counts)~date_range_start,
             data=newnaics_df,FUN=sum)
Months=c("January", "February", "March", "April", "May", "June", "July", "August")
monthly$Months<-Months
all(monthly$Months %in% month.name)
monthly$Months <- factor(monthly$Months, levels=month.name)
monthly

```

```{r}
#Import inflation data
inflation<-data.frame(inflation_rate=c(7.480,7.871,8.542,8.259,8.582,9.060,8.525,8.263),
                      Month=c("January", "February", "March", "April", "May", "June", "July", "August"))
all(inflation$Month %in% month.name)
inflation$Month <- factor(inflation$Month, levels=month.name)

```

```{r}
ggplot(data=inflation, aes(x=Month,y=inflation_rate, group=1)) +
  geom_line()+
  geom_point()

```
```{r}
ggplot(data=monthly, aes(x=Months,y=raw_visit_counts, group=1)) +
  geom_line()+
  geom_point()

### We can conclude that there is no correlation between coffee consumption and inflation.

```


