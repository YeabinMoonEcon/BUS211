{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 Thought experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = {}\n",
    "tfidf = dict(list(zip('cat dog apple lion NYC love'.split(), np.random.rand(6))))\n",
    "topic['pet'] = (.3 * tfidf['cat'] + .3 * tfidf['dog'] + 0 * tfidf['apple']\n",
    "                + 0 * tfidf['lion'] - .2 * tfidf['NYC'] + .2 * tfidf['love'])\n",
    "topic['animal'] = (.1 * tfidf['cat'] + .1 * tfidf['dog'] - .1 * tfidf['apple']\n",
    "                   + .5 * tfidf['lion'] + .1 * tfidf['NYC'] - .1 * tfidf['love'])\n",
    "topic['city'] = (0 * tfidf['cat'] - .1 * tfidf['dog'] + .2 * tfidf['apple']\n",
    "                 - .1 * tfidf['lion'] + .5 * tfidf['NYC'] + .1 * tfidf['love'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0.34877095731191854,\n",
       " 'dog': 0.3291225016687306,\n",
       " 'apple': 0.1976317267640031,\n",
       " 'lion': 0.9415194380646533,\n",
       " 'NYC': 0.9327241568469717,\n",
       " 'love': 0.9661496766140836}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pet': 0.2100531416476171,\n",
       " 'animal': 0.5154433402772802,\n",
       " 'city': 0.4754391974643564}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = {}\n",
    "word_vector['cat'] = .3 * topic['pet'] + .1 * topic['animal'] + 0 * topic['city']\n",
    "word_vector['dog'] = .3 * topic['pet'] + .1 * topic['animal'] - .1 * topic['city']\n",
    "word_vector['apple'] = 0 * topic['pet'] - .1 * topic['animal'] + .2 * topic['city']\n",
    "word_vector['lion'] = 0 * topic['pet'] + .5 * topic['animal'] - .1 * topic['city']\n",
    "word_vector['NYC'] = -.2 * topic['pet'] + .1 * topic['animal'] + .5 * topic['city']\n",
    "word_vector['love'] = .2 * topic['pet'] - .1 * topic['animal'] + .1 * topic['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0.19919446227030893,\n",
       " 'dog': 0.151789553594668,\n",
       " 'apple': 0.06417679396102252,\n",
       " 'lion': 0.10576020827565577,\n",
       " 'NYC': 0.15528327418176427,\n",
       " 'love': 0.12914617787208132}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.5 An LDA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = pd.read_csv('/Users/yeabinmoon/Documents/ibs_course/BUS243_NLP/nlpia-master/src/nlpia/data/sms-spam.csv',\n",
    "index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['sms{}{}'.format(i, '!'*j) for (i,j) in zip(range(len(sms)), sms.spam)]\n",
    "sms = pd.DataFrame(sms.values, columns=sms.columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam                                               text\n",
       "sms0     0  Go until jurong point, crazy.. Available only ...\n",
       "sms1     0                      Ok lar... Joking wif u oni...\n",
       "sms2!    1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "sms3     0  U dun say so early hor... U c already then say...\n",
       "sms4     0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4837, 9232)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "\n",
    "tfidf_model = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf_model.fit_transform(raw_documents=sms.text).toarray()\n",
    "tfidf_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.spam.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = sms.spam.astype(bool).values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_centroid = tfidf_docs[mask].mean(axis=0)\n",
    "ham_centroid = tfidf_docs[~mask].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9232"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9232"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06 0.   0.   ... 0.   0.   0.  ]\n",
      "[0.02 0.01 0.   ... 0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(spam_centroid.round(2))\n",
    "print(ham_centroid.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.39266024e-02, -1.92685506e-03,  3.84287194e-04, ...,\n",
       "       -6.31869803e-05, -6.31869803e-05, -6.31869803e-05])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_centroid - ham_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamminess_score = tfidf_docs.dot(spam_centroid - ham_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01, -0.02,  0.04, ..., -0.01, -0.  ,  0.  ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamminess_score.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sms['lda_score'] = MinMaxScaler().fit_transform(spamminess_score.reshape(-1,1))\n",
    "sms['lda_predict'] = (sms.lda_score > .5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "      <th>lda_score</th>\n",
       "      <th>lda_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0.227478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0.177888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0.718785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0.184565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0.286944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>0.850649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>0.292753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>0.269454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>0.331306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>0.399573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4837 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam                                               text  lda_score  \\\n",
       "0        0  Go until jurong point, crazy.. Available only ...   0.227478   \n",
       "1        0                      Ok lar... Joking wif u oni...   0.177888   \n",
       "2        1  Free entry in 2 a wkly comp to win FA Cup fina...   0.718785   \n",
       "3        0  U dun say so early hor... U c already then say...   0.184565   \n",
       "4        0  Nah I don't think he goes to usf, he lives aro...   0.286944   \n",
       "...    ...                                                ...        ...   \n",
       "4832     1  This is the 2nd time we have tried 2 contact u...   0.850649   \n",
       "4833     0               Will ü b going to esplanade fr home?   0.292753   \n",
       "4834     0  Pity, * was in mood for that. So...any other s...   0.269454   \n",
       "4835     0  The guy did some bitching but I acted like i'd...   0.331306   \n",
       "4836     0                         Rofl. Its true to its name   0.399573   \n",
       "\n",
       "      lda_predict  \n",
       "0               0  \n",
       "1               0  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "4832            1  \n",
       "4833            0  \n",
       "4834            0  \n",
       "4835            0  \n",
       "4836            0  \n",
       "\n",
       "[4837 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1. - (sms.spam - sms.lda_predict).abs().sum() / len(sms)).round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-dimensional plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, ' y')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "pca_model = PCA(n_components=3)\n",
    "tfidf_docs_3d = pca_model.fit_transform(tfidf_docs)\n",
    "df = pd.DataFrame(tfidf_docs_3d)\n",
    "ax = df[~mask].plot(x=0, y=1, kind='scatter', alpha=.5, c='green')\n",
    "df[mask].plot(x=0, y=1, ax=ax, alpha=.1, kind='scatter', c='red')\n",
    "plt.xlabel(' x')\n",
    "plt.ylabel(' y')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-dimensional plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lda_spam_3d_scatter.html'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly as py\n",
    "spam_trace = dict(\n",
    "        x=df[0][mask], y=df[1][mask], z=df[2][mask],\n",
    "        type=\"scatter3d\", mode='markers',\n",
    "        marker= dict(size=3, color='red', line=dict(width=0)) \n",
    "    )\n",
    "ham_trace = dict(\n",
    "        x=df[0][~mask], y=df[1][~mask], z=df[2][~mask],\n",
    "        type=\"scatter3d\", mode='markers',\n",
    "        marker= dict(size=3, color='green', line=dict(width=0)) \n",
    "    )\n",
    "fig = dict(data=[ham_trace, spam_trace], layout={'title': 'LDA Spamminess Model'})\n",
    "py.offline.plot(fig, filename='lda_spam_3d_scatter.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Singular value decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 19:12:41.818328: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pugnlp/constants.py:136: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  [datetime.datetime, pd.datetime, pd.Timestamp])\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pugnlp/constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pugnlp/tutil.py:100: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  np = pd.np\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pugnlp/util.py:80: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  np = pd.np\n",
      "/opt/anaconda3/lib/python3.9/site-packages/nlpia/futil.py:30: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  np = pd.np\n",
      "/opt/anaconda3/lib/python3.9/site-packages/nlpia/loaders.py:78: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  np = pd.np\n",
      "100%|██████████| 263/263 [00:00<00:00, 267808.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from nlpia.book.examples.ch04_catdog_lsa_sorted import lsa_models, prettify_tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:00<00:00, 261398.57it/s]\n"
     ]
    }
   ],
   "source": [
    "bow_svd, tfidf_svd = lsa_models()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>apple</th>\n",
       "      <th>lion</th>\n",
       "      <th>nyc</th>\n",
       "      <th>love</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>NYC is the Big Apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>NYC is known as the Big Apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I love NYC!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>I wore a hat to the Big Apple party in NYC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Come to NYC. See the Big Apple!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Manhattan is called the Big Apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>New York is a big city for a small cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The lion, a big cat, is the king of the jungle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>I love my pet cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I love New York City (NYC).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Your dog chased my cat.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat dog apple lion nyc love                                             text\n",
       "0              1        1                                 NYC is the Big Apple.\n",
       "1              1        1                        NYC is known as the Big Apple.\n",
       "2                       1    1                                      I love NYC!\n",
       "3              1        1           I wore a hat to the Big Apple party in NYC.\n",
       "4              1        1                       Come to NYC. See the Big Apple!\n",
       "5              1                             Manhattan is called the Big Apple.\n",
       "6    1                                  New York is a big city for a small cat.\n",
       "7    1              1           The lion, a big cat, is the king of the jungle.\n",
       "8    1                       1                               I love my pet cat.\n",
       "9                       1    1                      I love New York City (NYC).\n",
       "10   1   1                                              Your dog chased my cat."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prettify_tdm(**bow_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm = bow_svd['tdm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyc</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2   3   4   5   6   7   8   9   10\n",
       "cat     0   0   0   0   0   0   1   1   1   0   1\n",
       "dog     0   0   0   0   0   0   0   0   0   0   1\n",
       "apple   1   1   0   1   1   1   0   0   0   0   0\n",
       "lion    0   0   0   0   0   0   0   1   0   0   0\n",
       "nyc     1   1   1   1   1   0   0   0   0   1   0\n",
       "love    0   0   1   0   0   0   0   0   1   1   0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "U, s, Vt = np.linalg.svd(tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyc</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5\n",
       "cat    0.04 -0.83 -0.38 -0.00  0.11  0.38\n",
       "dog    0.00 -0.21 -0.18 -0.71 -0.39 -0.52\n",
       "apple  0.62  0.21 -0.51  0.00  0.49 -0.27\n",
       "lion   0.00 -0.21 -0.18  0.71 -0.39 -0.52\n",
       "nyc    0.75  0.00  0.24 -0.00 -0.52  0.32\n",
       "love   0.22 -0.42  0.69  0.00  0.41 -0.37"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(U, index = tdm.index).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04, -0.83, -0.38, -0.  ,  0.11,  0.38],\n",
       "       [ 0.  , -0.21, -0.18, -0.71, -0.39, -0.52],\n",
       "       [ 0.62,  0.21, -0.51,  0.  ,  0.49, -0.27],\n",
       "       [ 0.  , -0.21, -0.18,  0.71, -0.39, -0.52],\n",
       "       [ 0.75,  0.  ,  0.24, -0.  , -0.52,  0.32],\n",
       "       [ 0.22, -0.42,  0.69,  0.  ,  0.41, -0.37]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44,  0.44,  0.31,  0.44,  0.44,  0.2 ,  0.01,  0.01,  0.08,\n",
       "         0.31,  0.01],\n",
       "       [ 0.09,  0.09, -0.19,  0.09,  0.09,  0.09, -0.37, -0.47, -0.56,\n",
       "        -0.19, -0.47],\n",
       "       [-0.16, -0.16,  0.52, -0.16, -0.16, -0.29, -0.22, -0.32,  0.17,\n",
       "         0.52, -0.32],\n",
       "       [-0.  , -0.  , -0.  , -0.  , -0.  ,  0.  , -0.  ,  0.71,  0.  ,\n",
       "        -0.  , -0.71],\n",
       "       [-0.04, -0.04, -0.14, -0.04, -0.04,  0.58,  0.13, -0.33,  0.62,\n",
       "        -0.14, -0.33],\n",
       "       [ 0.09,  0.09, -0.1 ,  0.09,  0.09, -0.51,  0.73, -0.27,  0.01,\n",
       "        -0.1 , -0.27],\n",
       "       [-0.42, -0.44,  0.09,  0.57,  0.01,  0.29,  0.29,  0.  , -0.29,\n",
       "         0.2 ,  0.  ],\n",
       "       [-0.33,  0.56,  0.16,  0.41, -0.54, -0.1 , -0.1 , -0.  ,  0.1 ,\n",
       "        -0.25,  0.  ],\n",
       "       [-0.49,  0.03, -0.27,  0.19,  0.59, -0.31, -0.31,  0.  ,  0.31,\n",
       "        -0.05,  0.  ],\n",
       "       [-0.11,  0.32, -0.61, -0.08, -0.19,  0.07,  0.07, -0.  , -0.07,\n",
       "         0.68, -0.  ],\n",
       "       [-0.47,  0.39,  0.3 , -0.49,  0.3 ,  0.26,  0.26,  0.  , -0.26,\n",
       "        -0.04, -0.  ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6) 6 (11, 11)\n"
     ]
    }
   ],
   "source": [
    "print(U.shape, len(s), Vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.zeros((len(U),len(Vt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9    10\n",
       "0  3.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1  0.0  2.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  1.8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  0.8  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "5  0.0  0.0  0.0  0.0  0.0  0.5  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fill_diagonal(S,s)\n",
    "pd.DataFrame(S).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 11)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     10\n",
       "0   0.44  0.44  0.31  0.44  0.44  0.20  0.01  0.01  0.08  0.31  0.01\n",
       "1   0.09  0.09 -0.19  0.09  0.09  0.09 -0.37 -0.47 -0.56 -0.19 -0.47\n",
       "2  -0.16 -0.16  0.52 -0.16 -0.16 -0.29 -0.22 -0.32  0.17  0.52 -0.32\n",
       "3  -0.00 -0.00 -0.00 -0.00 -0.00  0.00 -0.00  0.71  0.00 -0.00 -0.71\n",
       "4  -0.04 -0.04 -0.14 -0.04 -0.04  0.58  0.13 -0.33  0.62 -0.14 -0.33\n",
       "5   0.09  0.09 -0.10  0.09  0.09 -0.51  0.73 -0.27  0.01 -0.10 -0.27\n",
       "6  -0.42 -0.44  0.09  0.57  0.01  0.29  0.29  0.00 -0.29  0.20  0.00\n",
       "7  -0.33  0.56  0.16  0.41 -0.54 -0.10 -0.10 -0.00  0.10 -0.25  0.00\n",
       "8  -0.49  0.03 -0.27  0.19  0.59 -0.31 -0.31  0.00  0.31 -0.05  0.00\n",
       "9  -0.11  0.32 -0.61 -0.08 -0.19  0.07  0.07 -0.00 -0.07  0.68 -0.00\n",
       "10 -0.47  0.39  0.30 -0.49  0.30  0.26  0.26  0.00 -0.26 -0.04 -0.00"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Vt).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.06, 0.12, 0.17, 0.28, 0.39, 0.55])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = [0]\n",
    "for numdim in range(len(s), 0, -1):\n",
    "    S[numdim - 1, numdim - 1] = 0\n",
    "    reconstructed_tdm = U.dot(S).dot(Vt)\n",
    "    err.append(np.sqrt(((reconstructed_tdm - tdm).values.flatten() ** 2).sum()/ np.product(tdm.shape)))\n",
    "np.array(err).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.07, 0.11, 0.15, 0.23, 0.3 , 0.41])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using tfidf tdm\n",
    "tdm = tfidf_svd['tdm']\n",
    "U, s, Vt = np.linalg.svd(tdm)\n",
    "S = np.zeros((len(U), len(Vt)))\n",
    "np.fill_diagonal(S, s)\n",
    "err2 = [0]\n",
    "for numdim in range(len(s), 0, -1):\n",
    "    S[numdim - 1, numdim - 1] = 0\n",
    "    reconstructed_tdm = U.dot(S).dot(Vt)\n",
    "    err2.append(np.sqrt(((reconstructed_tdm - tdm).values.flatten() ** 2).sum() / np.product(tdm.shape)))\n",
    "np.array(err2).round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              x         y         z\n",
      "46533  0.015047 -0.043478 -0.002522\n",
      "33564 -0.007327  0.062038  0.049706\n",
      "40075 -0.026133  0.071840  0.061419\n",
      "4929  -0.011138 -0.057819 -0.002953\n",
      "25228 -0.004825 -0.053159  0.029444\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 6)\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from nlpia.data.loaders import get_data\n",
    "\n",
    "df = get_data('pointcloud').sample(1000)\n",
    "print(df.head())\n",
    "pca = PCA(n_components=2)\n",
    "df2d = pd.DataFrame(pca.fit_transform(df), columns=list('xy'))\n",
    "df2d.plot(kind='scatter', x='x', y='y')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.2 Stop horsing around and get back to NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.width = 120 \n",
    "\n",
    "sms = pd.read_csv('/Users/yeabinmoon/Documents/ibs_course/BUS243_NLP/nlpia-master/src/nlpia/data/sms-spam.csv',\n",
    "index_col=0)\n",
    "index = ['sms{}{}'.format(i, '!'*j) for (i,j) in zip(range(len(sms)), sms.spam)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4832!</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4833</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4834</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4835</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4836</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4837 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          spam                                               text\n",
       "sms0         0  Go until jurong point, crazy.. Available only ...\n",
       "sms1         0                      Ok lar... Joking wif u oni...\n",
       "sms2!        1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "sms3         0  U dun say so early hor... U c already then say...\n",
       "sms4         0  Nah I don't think he goes to usf, he lives aro...\n",
       "...        ...                                                ...\n",
       "sms4832!     1  This is the 2nd time we have tried 2 contact u...\n",
       "sms4833      0               Will ü b going to esplanade fr home?\n",
       "sms4834      0  Pity, * was in mood for that. So...any other s...\n",
       "sms4835      0  The guy did some bitching but I acted like i'd...\n",
       "sms4836      0                         Rofl. Its true to its name\n",
       "\n",
       "[4837 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4837, 9232)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9232"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_docs = pd.DataFrame(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centering\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.spam.sum()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=16)\n",
    "pca_topic_vectors = pca.fit_transform(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  topic9  topic10  topic11  topic12  \\\n",
       "sms0    0.201   0.003   0.037   0.011  -0.019  -0.053   0.039  -0.066   0.009  -0.083    0.009   -0.007   -0.034   \n",
       "sms1    0.404  -0.094  -0.078   0.051   0.100   0.047   0.023   0.065   0.024  -0.026   -0.008    0.038   -0.036   \n",
       "sms2!  -0.030  -0.048   0.090  -0.067   0.091  -0.043  -0.000  -0.001  -0.055   0.052    0.129    0.020   -0.038   \n",
       "sms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  -0.166  -0.074   0.064  -0.111    0.014    0.026   -0.074   \n",
       "sms4    0.002   0.031   0.038   0.034  -0.075  -0.093  -0.044   0.062  -0.044   0.029    0.027   -0.006    0.008   \n",
       "sms5!  -0.016   0.058   0.014  -0.006   0.122  -0.040   0.005   0.166  -0.022   0.066    0.048    0.051    0.071   \n",
       "\n",
       "       topic13  topic14  topic15  \n",
       "sms0    -0.017   -0.024    0.027  \n",
       "sms1     0.011    0.056   -0.042  \n",
       "sms2!    0.011   -0.045    0.046  \n",
       "sms3     0.019    0.033   -0.068  \n",
       "sms4     0.048   -0.081   -0.028  \n",
       "sms5!    0.029    0.006    0.032  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 9232)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.07109825,  0.00818014, -0.00121146, ...,  0.00057176,\n",
       "         0.00057176,  0.00057176],\n",
       "       [ 0.06318977,  0.00777061,  0.00026513, ...,  0.00102076,\n",
       "         0.00102076,  0.00102076],\n",
       "       [ 0.07097967,  0.02684327,  0.00013358, ..., -0.00095356,\n",
       "        -0.00095356, -0.00095356],\n",
       "       ...,\n",
       "       [-0.06491723, -0.02701747,  0.00351994, ...,  0.00110426,\n",
       "         0.00110426,  0.00110426],\n",
       "       [-0.01900378, -0.01108555,  0.00094728, ...,  0.00086274,\n",
       "         0.00086274,  0.00086274],\n",
       "       [ 0.02132156, -0.02053435,  0.00013996, ..., -0.00034661,\n",
       "        -0.00034661, -0.00034661]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the following matrix?\n",
    "print(pca.components_.shape)\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 3807,\n",
       " 'until': 8487,\n",
       " 'jurong': 4675,\n",
       " 'point': 6296,\n",
       " ',': 13,\n",
       " 'crazy': 2549,\n",
       " '..': 21,\n",
       " 'available': 1531,\n",
       " 'only': 5910,\n",
       " 'in': 4396,\n",
       " 'bugis': 1973,\n",
       " 'n': 5594,\n",
       " 'great': 3894,\n",
       " 'world': 8977,\n",
       " 'la': 4811,\n",
       " 'e': 3056,\n",
       " 'buffet': 1971,\n",
       " '...': 25,\n",
       " 'cine': 2277,\n",
       " 'there': 8071,\n",
       " 'got': 3855,\n",
       " 'amore': 1296,\n",
       " 'wat': 8736,\n",
       " 'ok': 5874,\n",
       " 'lar': 4848,\n",
       " 'joking': 4642,\n",
       " 'wif': 8875,\n",
       " 'u': 8395,\n",
       " 'oni': 5906,\n",
       " 'free': 3604,\n",
       " 'entry': 3195,\n",
       " '2': 471,\n",
       " 'a': 1054,\n",
       " 'wkly': 8933,\n",
       " 'comp': 2386,\n",
       " 'to': 8192,\n",
       " 'win': 8890,\n",
       " 'fa': 3328,\n",
       " 'cup': 2608,\n",
       " 'final': 3450,\n",
       " 'tkts': 8180,\n",
       " '21st': 497,\n",
       " 'may': 5272,\n",
       " '2005': 487,\n",
       " '.': 15,\n",
       " 'text': 8020,\n",
       " '87121': 948,\n",
       " 'receive': 6688,\n",
       " 'question': 6574,\n",
       " '(': 9,\n",
       " 'std': 7651,\n",
       " 'txt': 8379,\n",
       " 'rate': 6628,\n",
       " ')': 10,\n",
       " 't': 7889,\n",
       " '&': 7,\n",
       " \"c's\": 2020,\n",
       " 'apply': 1383,\n",
       " '08452810075': 115,\n",
       " 'over': 6003,\n",
       " '18': 438,\n",
       " \"'\": 8,\n",
       " 's': 6959,\n",
       " 'dun': 3041,\n",
       " 'say': 7034,\n",
       " 'so': 7438,\n",
       " 'early': 3069,\n",
       " 'hor': 4207,\n",
       " 'c': 2019,\n",
       " 'already': 1268,\n",
       " 'then': 8065,\n",
       " 'nah': 5606,\n",
       " 'i': 4311,\n",
       " \"don't\": 2948,\n",
       " 'think': 8092,\n",
       " 'he': 4048,\n",
       " 'goes': 3819,\n",
       " 'usf': 8537,\n",
       " 'lives': 5004,\n",
       " 'around': 1435,\n",
       " 'here': 4104,\n",
       " 'though': 8111,\n",
       " 'freemsg': 3613,\n",
       " 'hey': 4116,\n",
       " 'darling': 2666,\n",
       " \"it's\": 4535,\n",
       " 'been': 1693,\n",
       " '3': 591,\n",
       " \"week's\": 8788,\n",
       " 'now': 5784,\n",
       " 'and': 1310,\n",
       " 'no': 5732,\n",
       " 'word': 8967,\n",
       " 'back': 1584,\n",
       " '!': 0,\n",
       " \"i'd\": 4312,\n",
       " 'like': 4954,\n",
       " 'some': 7454,\n",
       " 'fun': 3677,\n",
       " 'you': 9158,\n",
       " 'up': 8489,\n",
       " 'for': 3552,\n",
       " 'it': 4533,\n",
       " 'still': 7674,\n",
       " '?': 1037,\n",
       " 'tb': 7955,\n",
       " 'xxx': 9097,\n",
       " 'chgs': 2230,\n",
       " 'send': 7127,\n",
       " '£': 9216,\n",
       " '1.50': 344,\n",
       " 'rcv': 6641,\n",
       " 'even': 3240,\n",
       " 'my': 5584,\n",
       " 'brother': 1942,\n",
       " 'is': 4519,\n",
       " 'not': 5769,\n",
       " 'speak': 7529,\n",
       " 'with': 8918,\n",
       " 'me': 5281,\n",
       " 'they': 8083,\n",
       " 'treat': 8312,\n",
       " 'aids': 1214,\n",
       " 'patent': 6106,\n",
       " 'as': 1452,\n",
       " 'per': 6148,\n",
       " 'your': 9171,\n",
       " 'request': 6796,\n",
       " 'melle': 5315,\n",
       " 'oru': 5968,\n",
       " 'minnaminunginte': 5386,\n",
       " 'nurungu': 5807,\n",
       " 'vettam': 8599,\n",
       " 'has': 4022,\n",
       " 'set': 7154,\n",
       " 'callertune': 2047,\n",
       " 'all': 1253,\n",
       " 'callers': 2046,\n",
       " 'press': 6418,\n",
       " '*': 11,\n",
       " '9': 982,\n",
       " 'copy': 2489,\n",
       " 'friends': 3634,\n",
       " 'winner': 8900,\n",
       " 'valued': 8569,\n",
       " 'network': 5678,\n",
       " 'customer': 2620,\n",
       " 'have': 4036,\n",
       " 'selected': 7113,\n",
       " 'receivea': 6689,\n",
       " '900': 986,\n",
       " 'prize': 6450,\n",
       " 'reward': 6851,\n",
       " 'claim': 2283,\n",
       " 'call': 2038,\n",
       " '09061701461': 263,\n",
       " 'code': 2344,\n",
       " 'kl341': 4771,\n",
       " 'valid': 8565,\n",
       " '12': 384,\n",
       " 'hours': 4226,\n",
       " 'had': 3965,\n",
       " 'mobile': 5441,\n",
       " '11': 371,\n",
       " 'months': 5484,\n",
       " 'or': 5946,\n",
       " 'more': 5489,\n",
       " 'r': 6590,\n",
       " 'entitled': 3192,\n",
       " 'update': 8495,\n",
       " 'the': 8052,\n",
       " 'latest': 4862,\n",
       " 'colour': 2364,\n",
       " 'mobiles': 5442,\n",
       " 'camera': 2058,\n",
       " 'co': 2333,\n",
       " 'on': 5897,\n",
       " '08002986030': 99,\n",
       " \"i'm\": 4314,\n",
       " 'gonna': 3834,\n",
       " 'be': 1669,\n",
       " 'home': 4176,\n",
       " 'soon': 7483,\n",
       " 'want': 8715,\n",
       " 'talk': 7921,\n",
       " 'about': 1076,\n",
       " 'this': 8100,\n",
       " 'stuff': 7741,\n",
       " 'anymore': 1350,\n",
       " 'tonight': 8235,\n",
       " 'k': 4683,\n",
       " \"i've\": 4316,\n",
       " 'cried': 2566,\n",
       " 'enough': 3182,\n",
       " 'today': 8199,\n",
       " 'six': 7341,\n",
       " 'chances': 2172,\n",
       " 'cash': 2116,\n",
       " 'from': 3652,\n",
       " '100': 354,\n",
       " '20,000': 482,\n",
       " 'pounds': 6357,\n",
       " '>': 1035,\n",
       " 'csh': 2584,\n",
       " '87575': 952,\n",
       " 'cost': 2501,\n",
       " '150p': 415,\n",
       " '/': 27,\n",
       " 'day': 2683,\n",
       " '6days': 827,\n",
       " '16': 431,\n",
       " '+': 12,\n",
       " 'tsandcs': 8344,\n",
       " 'reply': 6788,\n",
       " 'hl': 4148,\n",
       " '4': 659,\n",
       " 'info': 4433,\n",
       " 'urgent': 8513,\n",
       " 'won': 8950,\n",
       " '1': 337,\n",
       " 'week': 8787,\n",
       " 'membership': 5321,\n",
       " 'our': 5980,\n",
       " '100,000': 355,\n",
       " 'jackpot': 4564,\n",
       " ':': 1006,\n",
       " '81010': 900,\n",
       " 'www.dbuk.net': 9039,\n",
       " 'lccltd': 4880,\n",
       " 'pobox': 6286,\n",
       " '4403ldnw1a7rw18': 696,\n",
       " 'searching': 7081,\n",
       " 'right': 6863,\n",
       " 'words': 8968,\n",
       " 'thank': 8037,\n",
       " 'breather': 1912,\n",
       " 'promise': 6487,\n",
       " 'wont': 8958,\n",
       " 'take': 7913,\n",
       " 'help': 4089,\n",
       " 'granted': 3883,\n",
       " 'will': 8887,\n",
       " 'fulfil': 3673,\n",
       " 'wonderful': 8955,\n",
       " 'blessing': 1802,\n",
       " 'at': 1488,\n",
       " 'times': 8158,\n",
       " 'date': 2675,\n",
       " 'sunday': 7805,\n",
       " 'xxxmobilemovieclub': 9098,\n",
       " 'use': 8531,\n",
       " 'credit': 2556,\n",
       " 'click': 2306,\n",
       " 'wap': 8719,\n",
       " 'link': 4977,\n",
       " 'next': 5696,\n",
       " 'message': 5340,\n",
       " 'http://wap': 4259,\n",
       " 'xxxmobilemovieclub.com': 9099,\n",
       " '=': 1031,\n",
       " 'qjkgighjjgcbl': 6566,\n",
       " 'oh': 5869,\n",
       " 'watching': 8743,\n",
       " ':)': 1008,\n",
       " 'eh': 3116,\n",
       " 'remember': 6755,\n",
       " 'how': 4233,\n",
       " 'spell': 7545,\n",
       " 'his': 4139,\n",
       " 'name': 5612,\n",
       " 'yes': 9137,\n",
       " 'did': 2823,\n",
       " 'v': 8553,\n",
       " 'naughty': 5635,\n",
       " 'make': 5193,\n",
       " 'wet': 8828,\n",
       " 'fine': 3458,\n",
       " 'if': 4350,\n",
       " 'that': 8045,\n",
       " '\\x92': 9211,\n",
       " 'way': 8753,\n",
       " 'feel': 3400,\n",
       " 'its': 4546,\n",
       " 'gota': 3856,\n",
       " 'b': 1560,\n",
       " 'england': 3173,\n",
       " 'macedonia': 5156,\n",
       " '-': 14,\n",
       " 'dont': 2952,\n",
       " 'miss': 5402,\n",
       " 'goals': 3812,\n",
       " 'team': 7968,\n",
       " 'news': 5692,\n",
       " 'ur': 8510,\n",
       " 'national': 5629,\n",
       " '87077': 947,\n",
       " 'eg': 3109,\n",
       " 'try': 8340,\n",
       " 'wales': 8695,\n",
       " 'scotland': 7060,\n",
       " '4txt': 737,\n",
       " 'ú1': 9220,\n",
       " '20': 481,\n",
       " 'poboxox': 6287,\n",
       " '36504w45wq': 629,\n",
       " 'seriously': 7147,\n",
       " '‘': 9225,\n",
       " 'm': 5139,\n",
       " 'going': 3823,\n",
       " 'ha': 3961,\n",
       " 'ü': 9221,\n",
       " 'pay': 6119,\n",
       " 'first': 3476,\n",
       " 'when': 8840,\n",
       " 'da': 2639,\n",
       " 'stock': 7678,\n",
       " 'comin': 2376,\n",
       " 'aft': 1182,\n",
       " 'finish': 3462,\n",
       " 'lunch': 5121,\n",
       " 'str': 7702,\n",
       " 'down': 2974,\n",
       " 'lor': 5058,\n",
       " 'ard': 1410,\n",
       " 'smth': 7422,\n",
       " 'ffffffffff': 3420,\n",
       " 'alright': 1269,\n",
       " 'can': 2062,\n",
       " 'meet': 5303,\n",
       " 'sooner': 7485,\n",
       " 'just': 4677,\n",
       " 'forced': 3554,\n",
       " 'myself': 5591,\n",
       " 'eat': 3081,\n",
       " 'slice': 7372,\n",
       " 'really': 6670,\n",
       " 'hungry': 4287,\n",
       " 'tho': 8107,\n",
       " 'sucks': 7778,\n",
       " 'mark': 5230,\n",
       " 'getting': 3767,\n",
       " 'worried': 8981,\n",
       " 'knows': 4782,\n",
       " 'sick': 7289,\n",
       " 'turn': 8362,\n",
       " 'pizza': 6238,\n",
       " 'lol': 5035,\n",
       " 'always': 1279,\n",
       " 'convincing': 2476,\n",
       " 'catch': 2128,\n",
       " 'bus': 1993,\n",
       " 'are': 1411,\n",
       " 'frying': 3660,\n",
       " 'an': 1305,\n",
       " 'egg': 3111,\n",
       " 'tea': 7962,\n",
       " 'eating': 3084,\n",
       " \"mom's\": 5463,\n",
       " 'left': 4901,\n",
       " 'dinner': 2858,\n",
       " 'do': 2909,\n",
       " 'love': 5081,\n",
       " \"we're\": 8760,\n",
       " 'packing': 6032,\n",
       " 'car': 2085,\n",
       " \"i'll\": 4313,\n",
       " 'let': 4923,\n",
       " 'know': 4779,\n",
       " \"there's\": 8074,\n",
       " 'room': 6906,\n",
       " 'ahhh': 1209,\n",
       " 'work': 8970,\n",
       " 'vaguely': 8560,\n",
       " 'what': 8832,\n",
       " 'does': 2923,\n",
       " 'wait': 8689,\n",
       " \"that's\": 8048,\n",
       " 'clear': 2300,\n",
       " 'were': 8817,\n",
       " 'sure': 7832,\n",
       " 'being': 1713,\n",
       " 'sarcastic': 7010,\n",
       " 'why': 8868,\n",
       " 'x': 9076,\n",
       " \"doesn't\": 2926,\n",
       " 'live': 5000,\n",
       " 'us': 8525,\n",
       " 'yeah': 9125,\n",
       " 'was': 8728,\n",
       " 'apologetic': 1371,\n",
       " 'fallen': 3352,\n",
       " 'out': 5983,\n",
       " 'she': 7199,\n",
       " 'actin': 1123,\n",
       " 'spoilt': 7572,\n",
       " 'child': 2238,\n",
       " 'caught': 2132,\n",
       " 'till': 8152,\n",
       " 'but': 1999,\n",
       " 'we': 8757,\n",
       " \"won't\": 8951,\n",
       " 'doing': 2938,\n",
       " 'too': 8242,\n",
       " 'badly': 1589,\n",
       " 'cheers': 2214,\n",
       " 'tell': 7985,\n",
       " 'anything': 1356,\n",
       " 'fear': 3391,\n",
       " 'of': 5847,\n",
       " 'fainting': 3344,\n",
       " 'housework': 4231,\n",
       " 'quick': 6577,\n",
       " 'cuppa': 2610,\n",
       " 'thanks': 8038,\n",
       " 'subscription': 7766,\n",
       " 'ringtone': 6872,\n",
       " 'uk': 8415,\n",
       " 'charged': 2184,\n",
       " '5': 745,\n",
       " 'month': 5479,\n",
       " 'please': 6265,\n",
       " 'confirm': 2431,\n",
       " 'by': 2016,\n",
       " 'replying': 6790,\n",
       " 'yup': 9192,\n",
       " 'look': 5046,\n",
       " 'timings': 8162,\n",
       " 'msg': 5528,\n",
       " 'again': 1190,\n",
       " 'xuhui': 9093,\n",
       " 'learn': 4892,\n",
       " '2nd': 567,\n",
       " 'her': 4099,\n",
       " 'lesson': 4921,\n",
       " '8am': 974,\n",
       " 'oops': 5921,\n",
       " \"roommate's\": 6909,\n",
       " 'done': 2950,\n",
       " 'see': 7098,\n",
       " 'letter': 4926,\n",
       " 'decide': 2711,\n",
       " 'hello': 4084,\n",
       " \"how's\": 4235,\n",
       " 'saturday': 7024,\n",
       " 'texting': 8027,\n",
       " \"you'd\": 9159,\n",
       " 'decided': 2712,\n",
       " 'tomo': 8224,\n",
       " 'trying': 8342,\n",
       " 'invite': 4493,\n",
       " 'pls': 6273,\n",
       " 'ahead': 1208,\n",
       " 'watts': 8751,\n",
       " 'wanted': 8716,\n",
       " 'weekend': 8791,\n",
       " 'abiola': 1072,\n",
       " 'forget': 3560,\n",
       " 'need': 5654,\n",
       " 'crave': 2546,\n",
       " 'most': 5499,\n",
       " 'sweet': 7863,\n",
       " 'arabian': 1407,\n",
       " 'steed': 7658,\n",
       " 'mmmmmm': 5431,\n",
       " 'yummy': 9187,\n",
       " '07732584351': 62,\n",
       " 'rodger': 6895,\n",
       " 'burns': 1990,\n",
       " 'tried': 8321,\n",
       " 're': 6645,\n",
       " 'sms': 7416,\n",
       " 'nokia': 5744,\n",
       " 'camcorder': 2056,\n",
       " '08000930705': 95,\n",
       " 'delivery': 2750,\n",
       " 'tomorrow': 8226,\n",
       " 'who': 8859,\n",
       " 'seeing': 7101,\n",
       " 'hope': 4198,\n",
       " 'man': 5203,\n",
       " 'well': 8807,\n",
       " 'endowed': 3163,\n",
       " 'am': 1281,\n",
       " '<#>': 1024,\n",
       " 'inches': 4401,\n",
       " 'calls': 2053,\n",
       " 'messages': 5344,\n",
       " 'missed': 5405,\n",
       " \"didn't\": 2828,\n",
       " 'get': 3760,\n",
       " 'hep': 4098,\n",
       " 'immunisation': 4379,\n",
       " 'nigeria': 5708,\n",
       " 'fair': 3345,\n",
       " 'hopefully': 4201,\n",
       " 'tyler': 8389,\n",
       " \"can't\": 2063,\n",
       " 'could': 2511,\n",
       " 'maybe': 5274,\n",
       " 'ask': 1463,\n",
       " 'bit': 1779,\n",
       " 'stubborn': 7730,\n",
       " 'hospital': 4214,\n",
       " 'kept': 4730,\n",
       " 'telling': 7986,\n",
       " 'weak': 8762,\n",
       " 'sucker': 7776,\n",
       " 'hospitals': 4215,\n",
       " 'suckers': 7777,\n",
       " 'thinked': 8093,\n",
       " 'time': 8154,\n",
       " 'saw': 7033,\n",
       " 'class': 2292,\n",
       " 'gram': 3875,\n",
       " 'usually': 8543,\n",
       " 'runs': 6949,\n",
       " 'half': 3977,\n",
       " 'eighth': 3119,\n",
       " 'smarter': 7395,\n",
       " 'gets': 3763,\n",
       " 'almost': 1264,\n",
       " 'whole': 8862,\n",
       " 'second': 7085,\n",
       " 'fyi': 3693,\n",
       " 'ride': 6862,\n",
       " 'morning': 5493,\n",
       " \"he's\": 4050,\n",
       " 'crashing': 2545,\n",
       " 'place': 6240,\n",
       " 'wow': 8997,\n",
       " 'never': 5683,\n",
       " 'realized': 6668,\n",
       " 'embarassed': 3144,\n",
       " 'accomodations': 1103,\n",
       " 'thought': 8112,\n",
       " 'liked': 4955,\n",
       " 'since': 7314,\n",
       " 'best': 1733,\n",
       " 'seemed': 7105,\n",
       " 'happy': 4011,\n",
       " '\"': 1,\n",
       " 'cave': 2136,\n",
       " 'sorry': 7494,\n",
       " 'give': 3788,\n",
       " 'offered': 5855,\n",
       " 'embarassing': 3145,\n",
       " 'ac': 1089,\n",
       " 'sptv': 7594,\n",
       " 'new': 5687,\n",
       " 'jersey': 4608,\n",
       " 'devils': 2803,\n",
       " 'detroit': 2797,\n",
       " 'red': 6711,\n",
       " 'wings': 8898,\n",
       " 'play': 6255,\n",
       " 'ice': 4330,\n",
       " 'hockey': 4161,\n",
       " 'correct': 2494,\n",
       " 'incorrect': 4412,\n",
       " 'end': 3158,\n",
       " 'mallika': 5202,\n",
       " 'sherawat': 7208,\n",
       " 'yesterday': 9141,\n",
       " 'find': 3455,\n",
       " '@': 1038,\n",
       " '<url>': 1030,\n",
       " 'congrats': 2437,\n",
       " 'year': 9126,\n",
       " 'special': 7531,\n",
       " 'cinema': 2278,\n",
       " 'pass': 6094,\n",
       " 'yours': 9176,\n",
       " '09061209465': 258,\n",
       " 'suprman': 7830,\n",
       " 'matrix': 5263,\n",
       " 'starwars': 7638,\n",
       " 'etc': 3230,\n",
       " 'bx420': 2014,\n",
       " 'ip4': 4502,\n",
       " '5we': 781,\n",
       " '150pm': 417,\n",
       " 'later': 4861,\n",
       " 'meeting': 5305,\n",
       " 'where': 8846,\n",
       " 'reached': 6652,\n",
       " 'gauti': 3728,\n",
       " 'sehwag': 7110,\n",
       " 'odi': 5846,\n",
       " 'series': 7145,\n",
       " 'pick': 6211,\n",
       " '$': 5,\n",
       " 'burger': 1985,\n",
       " 'yourself': 9177,\n",
       " 'move': 5513,\n",
       " 'pain': 6039,\n",
       " 'killing': 4754,\n",
       " 'good': 3836,\n",
       " 'joke': 4636,\n",
       " 'girls': 3785,\n",
       " 'situation': 7338,\n",
       " 'seekers': 7102,\n",
       " 'part': 6081,\n",
       " 'checking': 2208,\n",
       " 'iq': 4508,\n",
       " 'roommates': 6910,\n",
       " 'took': 8245,\n",
       " 'forever': 3557,\n",
       " 'come': 2371,\n",
       " 'double': 2966,\n",
       " 'check': 2204,\n",
       " 'hair': 3972,\n",
       " 'dresser': 2998,\n",
       " 'said': 6980,\n",
       " 'wun': 9024,\n",
       " 'cut': 2624,\n",
       " 'short': 7248,\n",
       " 'nice': 5701,\n",
       " 'pleased': 6266,\n",
       " 'advise': 1165,\n",
       " 'following': 3534,\n",
       " 'recent': 6692,\n",
       " 'review': 6849,\n",
       " 'mob': 5439,\n",
       " 'awarded': 1549,\n",
       " '1500': 414,\n",
       " 'bonus': 1844,\n",
       " '09066364589': 306,\n",
       " 'song': 7478,\n",
       " 'dedicated': 2722,\n",
       " 'which': 8853,\n",
       " 'dedicate': 2721,\n",
       " 'valuable': 8566,\n",
       " 'frnds': 3643,\n",
       " 'rply': 6925,\n",
       " 'complimentary': 2406,\n",
       " 'trip': 8322,\n",
       " 'eurodisinc': 3234,\n",
       " 'trav': 8304,\n",
       " 'aco': 1119,\n",
       " '41': 679,\n",
       " '1000': 356,\n",
       " 'dis': 2871,\n",
       " '6': 785,\n",
       " 'morefrmmob': 5490,\n",
       " 'shracomorsglsuplt': 7273,\n",
       " '10': 350,\n",
       " 'ls1': 5103,\n",
       " '3aj': 638,\n",
       " 'hear': 4062,\n",
       " 'divorce': 2900,\n",
       " 'barbie': 1620,\n",
       " 'comes': 2373,\n",
       " \"ken's\": 4728,\n",
       " 'plane': 6247,\n",
       " 'wah': 8682,\n",
       " 'lucky': 5114,\n",
       " 'save': 7029,\n",
       " 'money': 5470,\n",
       " 'hee': 4075,\n",
       " 'finished': 3464,\n",
       " 'hi': 4120,\n",
       " 'babe': 1574,\n",
       " 'im': 4368,\n",
       " 'wanna': 8713,\n",
       " 'something': 7464,\n",
       " 'xx': 9094,\n",
       " 'performed': 6155,\n",
       " 'waiting': 8692,\n",
       " 'machan': 5158,\n",
       " 'once': 5901,\n",
       " 'thats': 8051,\n",
       " 'cool': 2481,\n",
       " 'gentleman': 3751,\n",
       " 'dignity': 2848,\n",
       " 'respect': 6816,\n",
       " 'peoples': 6147,\n",
       " 'very': 8598,\n",
       " 'much': 5544,\n",
       " 'shy': 7283,\n",
       " 'pa': 6027,\n",
       " 'operate': 5928,\n",
       " 'after': 1183,\n",
       " 'same': 6996,\n",
       " 'looking': 5050,\n",
       " 'job': 4623,\n",
       " \"ta's\": 7896,\n",
       " 'earn': 3070,\n",
       " 'ah': 1204,\n",
       " 'stop': 7688,\n",
       " 'urgnt': 8517,\n",
       " 'real': 6662,\n",
       " 'yo': 9152,\n",
       " 'tickets': 8142,\n",
       " 'one': 5903,\n",
       " 'jacket': 4563,\n",
       " 'used': 8532,\n",
       " 'multis': 5553,\n",
       " 'started': 7632,\n",
       " 'requests': 6797,\n",
       " 'came': 2057,\n",
       " 'bed': 1686,\n",
       " 'coins': 2350,\n",
       " 'factory': 3335,\n",
       " 'gotta': 3860,\n",
       " 'nitros': 5727,\n",
       " 'ela': 3124,\n",
       " 'kano': 4708,\n",
       " 'il': 4362,\n",
       " 'download': 2975,\n",
       " 'wen': 8811,\n",
       " 'don': 2947,\n",
       " 'stand': 7620,\n",
       " 'close': 2313,\n",
       " 'll': 5008,\n",
       " 'another': 1332,\n",
       " 'night': 5710,\n",
       " 'spent': 7550,\n",
       " 'late': 4858,\n",
       " 'afternoon': 1185,\n",
       " 'casualty': 2126,\n",
       " 'means': 5291,\n",
       " \"haven't\": 4039,\n",
       " 'any': 1346,\n",
       " 'y': 9107,\n",
       " '42moro': 689,\n",
       " 'includes': 4405,\n",
       " 'sheets': 7203,\n",
       " 'smile': 7403,\n",
       " 'pleasure': 6268,\n",
       " 'trouble': 8328,\n",
       " 'pours': 6359,\n",
       " 'rain': 6602,\n",
       " 'sum': 7798,\n",
       " 'hurts': 4297,\n",
       " 'becoz': 1684,\n",
       " 'someone': 7457,\n",
       " 'loves': 5090,\n",
       " 'smiling': 7407,\n",
       " 'service': 7150,\n",
       " 'representative': 6794,\n",
       " '0800 169 6031': 86,\n",
       " 'between': 1741,\n",
       " '10am': 365,\n",
       " '9pm': 1002,\n",
       " 'guaranteed': 3930,\n",
       " '5000': 755,\n",
       " 'havent': 4040,\n",
       " 'planning': 6251,\n",
       " 'buy': 2004,\n",
       " 'lido': 4937,\n",
       " '530': 767,\n",
       " 'show': 7264,\n",
       " 'collected': 2358,\n",
       " 'simply': 7311,\n",
       " 'password': 6102,\n",
       " 'mix': 5421,\n",
       " '85069': 934,\n",
       " 'verify': 8594,\n",
       " 'usher': 8538,\n",
       " 'britney': 1932,\n",
       " 'fml': 3525,\n",
       " 'po': 6284,\n",
       " 'box': 1879,\n",
       " '5249': 764,\n",
       " 'mk17': 5424,\n",
       " '92h': 990,\n",
       " '450ppw': 705,\n",
       " 'telugu': 7991,\n",
       " 'movie': 5516,\n",
       " 'abt': 1084,\n",
       " 'loads': 5014,\n",
       " 'loans': 5016,\n",
       " 'wk': 8928,\n",
       " 'hols': 4174,\n",
       " 'run': 6946,\n",
       " 'forgot': 3565,\n",
       " 'hairdressers': 3974,\n",
       " 'appointment': 1386,\n",
       " 'four': 3584,\n",
       " 'shower': 7266,\n",
       " 'beforehand': 1702,\n",
       " 'cause': 2133,\n",
       " 'prob': 6456,\n",
       " 'coffee': 2345,\n",
       " 'animation': 1319,\n",
       " 'nothing': 5774,\n",
       " 'else': 3138,\n",
       " 'okay': 5877,\n",
       " 'price': 6431,\n",
       " 'long': 5042,\n",
       " 'legal': 4904,\n",
       " 'them': 8061,\n",
       " 'ave': 1536,\n",
       " 'ams': 1301,\n",
       " 'gone': 3832,\n",
       " '4the': 735,\n",
       " 'driving': 3007,\n",
       " 'test': 8014,\n",
       " 'yet': 9142,\n",
       " \"you're\": 9162,\n",
       " 'mean': 5287,\n",
       " 'guess': 3936,\n",
       " 'gave': 3729,\n",
       " 'boston': 1866,\n",
       " 'men': 5326,\n",
       " 'changed': 2174,\n",
       " 'search': 7080,\n",
       " 'location': 5019,\n",
       " 'nyc': 5819,\n",
       " 'cuz': 2631,\n",
       " 'signin': 7299,\n",
       " 'page': 6035,\n",
       " 'says': 7038,\n",
       " 'umma': 8423,\n",
       " 'life': 4940,\n",
       " 'vava': 8580,\n",
       " 'lot': 5066,\n",
       " 'dear': 2699,\n",
       " 'wishes': 8912,\n",
       " 'birthday': 1777,\n",
       " 'making': 5197,\n",
       " 'truly': 8335,\n",
       " 'memorable': 5323,\n",
       " 'aight': 1216,\n",
       " 'hit': 4141,\n",
       " 'would': 8993,\n",
       " 'ip': 4501,\n",
       " 'address': 1141,\n",
       " 'considering': 2449,\n",
       " 'computer': 2412,\n",
       " \"isn't\": 4528,\n",
       " 'minecraft': 5380,\n",
       " 'server': 7149,\n",
       " 'grumpy': 3923,\n",
       " 'old': 5889,\n",
       " 'people': 6146,\n",
       " 'mom': 5462,\n",
       " 'better': 1738,\n",
       " 'lying': 5135,\n",
       " 'jokes': 4640,\n",
       " 'worry': 8983,\n",
       " 'busy': 1998,\n",
       " 'plural': 6277,\n",
       " 'noun': 5781,\n",
       " 'research': 6802,\n",
       " 'dinner.msg': 2859,\n",
       " 'cos': 2499,\n",
       " 'things': 8091,\n",
       " 'scared': 7044,\n",
       " 'mah': 5180,\n",
       " 'loud': 5076,\n",
       " 'gent': 3749,\n",
       " 'contact': 2454,\n",
       " 'last': 4855,\n",
       " 'weekends': 8793,\n",
       " 'draw': 2989,\n",
       " 'shows': 7272,\n",
       " '09064012160': 282,\n",
       " 'k52': 4691,\n",
       " '12hrs': 398,\n",
       " '150ppm': 419,\n",
       " 'wa': 8677,\n",
       " 'openin': 5925,\n",
       " 'sentence': 7138,\n",
       " 'formal': 3569,\n",
       " 'anyway': 1360,\n",
       " 'juz': 4682,\n",
       " 'tt': 8348,\n",
       " 'eatin': 3083,\n",
       " 'puttin': 6554,\n",
       " 'weight': 8798,\n",
       " 'haha': 3968,\n",
       " 'anythin': 1355,\n",
       " 'happened': 4003,\n",
       " 'entered': 3185,\n",
       " 'cabin': 2025,\n",
       " \"b'day\": 1562,\n",
       " 'boss': 1865,\n",
       " 'felt': 3411,\n",
       " 'askd': 1464,\n",
       " 'invited': 4494,\n",
       " 'apartment': 1365,\n",
       " 'went': 8814,\n",
       " 'specially': 7536,\n",
       " 'holiday': 4171,\n",
       " 'flights': 3502,\n",
       " 'inc': 4399,\n",
       " 'operator': 5929,\n",
       " '08712778109': 166,\n",
       " '10p': 368,\n",
       " 'min': 5372,\n",
       " 'goodo': 3846,\n",
       " 'must': 5575,\n",
       " 'friday': 3626,\n",
       " 'egg-potato': 3112,\n",
       " 'ratio': 6631,\n",
       " 'tortilla': 8262,\n",
       " 'needed': 5656,\n",
       " 'hmm': 4153,\n",
       " 'uncle': 8433,\n",
       " 'informed': 4438,\n",
       " 'paying': 6124,\n",
       " 'school': 7050,\n",
       " 'directly': 2865,\n",
       " 'food': 3542,\n",
       " 'private': 6447,\n",
       " '2004': 486,\n",
       " 'account': 1107,\n",
       " 'statement': 7641,\n",
       " '07742676969': 64,\n",
       " '786': 864,\n",
       " 'unredeemed': 8477,\n",
       " 'points': 6297,\n",
       " '08719180248': 213,\n",
       " 'identifier': 4344,\n",
       " '45239': 707,\n",
       " 'expires': 3307,\n",
       " '2000': 484,\n",
       " 'caller': 2045,\n",
       " '5/9': 752,\n",
       " '03': 46,\n",
       " 'landline': 4835,\n",
       " '09064019788': 288,\n",
       " '42wr29c': 690,\n",
       " 'apples': 1381,\n",
       " 'pairs': 6044,\n",
       " 'malarky': 5199,\n",
       " 'todays': 8205,\n",
       " 'voda': 8645,\n",
       " 'numbers': 5804,\n",
       " 'ending': 3160,\n",
       " '7548': 856,\n",
       " '350': 624,\n",
       " 'award': 1548,\n",
       " 'match': 5251,\n",
       " '08712300220': 149,\n",
       " 'quoting': 6589,\n",
       " '4041': 674,\n",
       " 'standard': 7621,\n",
       " 'rates': 6629,\n",
       " 'app': 1375,\n",
       " 'sao': 7004,\n",
       " 'mu': 5542,\n",
       " 'predict': 6392,\n",
       " \"ü'll\": 9222,\n",
       " 'buying': 2007,\n",
       " 'yetunde': 9144,\n",
       " \"hasn't\": 4024,\n",
       " 'sent': 7137,\n",
       " 'bother': 1869,\n",
       " 'sending': 7129,\n",
       " 'involve': 4498,\n",
       " \"shouldn't\": 7259,\n",
       " 'imposed': 4386,\n",
       " 'apologise': 1372,\n",
       " 'girl': 3782,\n",
       " 'del': 2740,\n",
       " 'bak': 1597,\n",
       " 'lucyxx': 5118,\n",
       " 'tmorrow.pls': 8185,\n",
       " 'accomodate': 1102,\n",
       " 'answer': 1335,\n",
       " 'sunshine': 7812,\n",
       " 'quiz': 6584,\n",
       " 'q': 6559,\n",
       " 'top': 8253,\n",
       " 'sony': 7480,\n",
       " 'dvd': 3051,\n",
       " 'player': 6257,\n",
       " 'country': 2518,\n",
       " 'algarve': 1245,\n",
       " 'ansr': 1334,\n",
       " '82277': 907,\n",
       " 'sp': 7516,\n",
       " 'tyrone': 8394,\n",
       " 'laid': 4827,\n",
       " 'dogging': 2932,\n",
       " 'locations': 5020,\n",
       " 'direct': 2864,\n",
       " 'join': 4631,\n",
       " \"uk's\": 8416,\n",
       " 'largest': 4852,\n",
       " 'bt': 1958,\n",
       " 'txting': 8383,\n",
       " 'gravel': 3888,\n",
       " '69888': 822,\n",
       " 'nt': 5791,\n",
       " 'ec2a': 3086,\n",
       " '31p': 611,\n",
       " '@150p': 1039,\n",
       " 'haf': 3967,\n",
       " 'msn': 5534,\n",
       " 'yijue@hotmail.com': 9149,\n",
       " 'him': 4132,\n",
       " 'rooms': 6911,\n",
       " 'befor': 1699,\n",
       " 'activities': 1129,\n",
       " \"you'll\": 9161,\n",
       " 'msgs': 5533,\n",
       " 'chat': 2195,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_nums, terms = zip(*sorted(zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('!',\n",
       " '\"',\n",
       " '#',\n",
       " '#150',\n",
       " '#5000',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '. .',\n",
       " '. . .',\n",
       " '. . . .',\n",
       " '. . . . .',\n",
       " '. ..',\n",
       " '..',\n",
       " '.. .',\n",
       " '.. . . .',\n",
       " '.. ... ...',\n",
       " '...',\n",
       " '... . . . .',\n",
       " '/',\n",
       " '0',\n",
       " '00',\n",
       " '00870405040',\n",
       " '0089',\n",
       " '01',\n",
       " '0121 2025050',\n",
       " '01223585236',\n",
       " '01223585334',\n",
       " '01256987',\n",
       " '02',\n",
       " '02/06',\n",
       " '02/09',\n",
       " '0207 153 9153',\n",
       " '0207 153 9996',\n",
       " '0207-083-6089',\n",
       " '02072069400',\n",
       " '02073162414',\n",
       " '02085076972',\n",
       " '03',\n",
       " '03530150',\n",
       " '04',\n",
       " '04/09',\n",
       " '05',\n",
       " '050703',\n",
       " '06',\n",
       " '06.05',\n",
       " '06/11',\n",
       " '07/11',\n",
       " '07008009200',\n",
       " '07046744435',\n",
       " '07090201529',\n",
       " '07090298926',\n",
       " '07099833605',\n",
       " '07123456789',\n",
       " '07732584351',\n",
       " '07734396839',\n",
       " '07742676969',\n",
       " '07753741225',\n",
       " '0776xxxxxxx',\n",
       " '07786200117',\n",
       " '077xxx',\n",
       " '078',\n",
       " '07801543489',\n",
       " '07808',\n",
       " '07808247860',\n",
       " '07808726822',\n",
       " '07815296484',\n",
       " '07821230901',\n",
       " '078498',\n",
       " '07880867867',\n",
       " '0789xxxxxxx',\n",
       " '07946746291',\n",
       " '0796xxxxxx',\n",
       " '07973788240',\n",
       " '07xxxxxxxxx',\n",
       " '08',\n",
       " '0800',\n",
       " '0800 0721072',\n",
       " '0800 169 6031',\n",
       " '0800 195 6669',\n",
       " '0800 1956669',\n",
       " '0800 5050',\n",
       " '0800 542 0578',\n",
       " '0800 542 0825',\n",
       " '08000407165',\n",
       " '08000776320',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '08000938767',\n",
       " '08001950382',\n",
       " '08002888812',\n",
       " '08002986030',\n",
       " '08002986906',\n",
       " '08002988890',\n",
       " '08006344447',\n",
       " '0808 145 4742',\n",
       " '08081263000',\n",
       " '08081560665',\n",
       " '0819',\n",
       " '0844',\n",
       " '08448350055',\n",
       " '08448714184',\n",
       " '0845 021 3680',\n",
       " '0845 2814032',\n",
       " '08450542832',\n",
       " '08452810071',\n",
       " '08452810073',\n",
       " '08452810075',\n",
       " '0870',\n",
       " '08700435505',\n",
       " '08700469649',\n",
       " '08700621170',\n",
       " '08701213186',\n",
       " '08701237397',\n",
       " '08701417012',\n",
       " '08701624',\n",
       " '08701752560',\n",
       " '08701872873',\n",
       " '08702411827',\n",
       " '08702490080',\n",
       " '08702840625',\n",
       " '08702840625.comuk',\n",
       " '08704050406',\n",
       " '08704439680',\n",
       " '08706091795',\n",
       " '08707379102',\n",
       " '08707500020',\n",
       " '08707509020',\n",
       " '08707533310',\n",
       " '08707808226',\n",
       " '08708034412',\n",
       " '08708800282',\n",
       " '08709222922',\n",
       " '08709501522',\n",
       " '0871-4719',\n",
       " '0871-872-9755',\n",
       " '0871-872-9758',\n",
       " '08710471114',\n",
       " '08712101358',\n",
       " '08712103738',\n",
       " '08712120250',\n",
       " '08712300220',\n",
       " '08712317606',\n",
       " '08712400200',\n",
       " '08712400602',\n",
       " '08712400603',\n",
       " '08712402050',\n",
       " '08712402578',\n",
       " '08712402779',\n",
       " '08712402902',\n",
       " '08712402972',\n",
       " '08712404000',\n",
       " '08712405020',\n",
       " '08712405022',\n",
       " '08712460324',\n",
       " '08712466669',\n",
       " '08712778107',\n",
       " '08712778108',\n",
       " '08712778109',\n",
       " '08714342399',\n",
       " '08714712377',\n",
       " '08714712379',\n",
       " '08714712388',\n",
       " '08714712394',\n",
       " '08714712412',\n",
       " '08714714011',\n",
       " '08714740323',\n",
       " '08714742804',\n",
       " '08715203028',\n",
       " '08715203649',\n",
       " '08715203652',\n",
       " '08715203656',\n",
       " '08715203677',\n",
       " '08715203685',\n",
       " '08715203694',\n",
       " '08715205273',\n",
       " '08715500022',\n",
       " '08715705022',\n",
       " '08717111821',\n",
       " '08717168528',\n",
       " '08717205546',\n",
       " '0871750',\n",
       " '08717507382',\n",
       " '08717509990',\n",
       " '08717890890',\n",
       " '08717895698',\n",
       " '08717898035',\n",
       " '08718711108',\n",
       " '08718720201',\n",
       " '08718723815',\n",
       " '08718725756',\n",
       " '08718726270',\n",
       " '08718726970',\n",
       " '08718726971',\n",
       " '08718726978',\n",
       " '08718727200',\n",
       " '08718727868',\n",
       " '08718727870',\n",
       " '08718728876',\n",
       " '08718730555',\n",
       " '08718730666',\n",
       " '08718738001',\n",
       " '08718738002',\n",
       " '08718738034',\n",
       " '08719180219',\n",
       " '08719180248',\n",
       " '08719181259',\n",
       " '08719181503',\n",
       " '08719181513',\n",
       " '08719839835',\n",
       " '08719899217',\n",
       " '08719899229',\n",
       " '08719899230',\n",
       " '09',\n",
       " '09041940223',\n",
       " '09050000301',\n",
       " '09050000327',\n",
       " '09050000332',\n",
       " '09050000460',\n",
       " '09050000555',\n",
       " '09050000878',\n",
       " '09050000928',\n",
       " '09050001295',\n",
       " '09050001808',\n",
       " '09050002311',\n",
       " '09050003091',\n",
       " '09050005321',\n",
       " '09050090044',\n",
       " '09050280520',\n",
       " '09053750005',\n",
       " '09056242159',\n",
       " '09057039994',\n",
       " '09058091854',\n",
       " '09058091870',\n",
       " '09058094454',\n",
       " '09058094455',\n",
       " '09058094507',\n",
       " '09058094565',\n",
       " '09058094583',\n",
       " '09058094594',\n",
       " '09058094597',\n",
       " '09058094599',\n",
       " '09058095107',\n",
       " '09058095201',\n",
       " '09058097189',\n",
       " '09058097218',\n",
       " '09058098002',\n",
       " '09058099801',\n",
       " '09061104276',\n",
       " '09061104283',\n",
       " '09061209465',\n",
       " '09061213237',\n",
       " '09061221061',\n",
       " '09061221066',\n",
       " '09061701444',\n",
       " '09061701461',\n",
       " '09061701851',\n",
       " '09061701939',\n",
       " '09061702893',\n",
       " '09061743386',\n",
       " '09061743806',\n",
       " '09061743810',\n",
       " '09061743811',\n",
       " '09061744553',\n",
       " '09061749602',\n",
       " '09061790121',\n",
       " '09061790125',\n",
       " '09061790126',\n",
       " '09063440451',\n",
       " '09063442151',\n",
       " '09063458130',\n",
       " '09063463',\n",
       " '09064011000',\n",
       " '09064012103',\n",
       " '09064012160',\n",
       " '09064015307',\n",
       " '09064017295',\n",
       " '09064017305',\n",
       " '09064018838',\n",
       " '09064019014',\n",
       " '09064019788',\n",
       " '09065069120',\n",
       " '09065069154',\n",
       " '09065171142',\n",
       " '09065174042',\n",
       " '09065394514',\n",
       " '09065394973',\n",
       " '09065989180',\n",
       " '09065989182',\n",
       " '09066350750',\n",
       " '09066358152',\n",
       " '09066358361',\n",
       " '09066361921',\n",
       " '09066362206',\n",
       " '09066362220',\n",
       " '09066362231',\n",
       " '09066364311',\n",
       " '09066364349',\n",
       " '09066364589',\n",
       " '09066368327',\n",
       " '09066368470',\n",
       " '09066368753',\n",
       " '09066380611',\n",
       " '09066382422',\n",
       " '09066612661',\n",
       " '09066649731',\n",
       " '09066660100',\n",
       " '09071512432',\n",
       " '09071512433',\n",
       " '09071517866',\n",
       " '09077818151',\n",
       " '09090204448',\n",
       " '09090900040',\n",
       " '09094100151',\n",
       " '09094646631',\n",
       " '09094646899',\n",
       " '09095350301',\n",
       " '09096102316',\n",
       " '09099725823',\n",
       " '09099726395',\n",
       " '09099726429',\n",
       " '09099726481',\n",
       " '09099726553',\n",
       " '09111030116',\n",
       " '09111032124',\n",
       " '09701213186',\n",
       " '0a',\n",
       " '0p',\n",
       " '0quit',\n",
       " '1',\n",
       " '1,000',\n",
       " '1,2',\n",
       " '1,50',\n",
       " '1,500',\n",
       " '1.20',\n",
       " '1.5',\n",
       " '1.50',\n",
       " '1.childish',\n",
       " '1/08',\n",
       " '1/1',\n",
       " '1/2',\n",
       " '1/3',\n",
       " '10',\n",
       " '10,000',\n",
       " '10.1',\n",
       " '10/06',\n",
       " '100',\n",
       " '100,000',\n",
       " '1000',\n",
       " '1000call',\n",
       " '1000s',\n",
       " '100p',\n",
       " '100txt',\n",
       " '1013',\n",
       " '1030',\n",
       " '10:10',\n",
       " '10:30',\n",
       " '10am',\n",
       " '10k',\n",
       " '10mins',\n",
       " '10p',\n",
       " '10ppm',\n",
       " '10th',\n",
       " '11',\n",
       " '11.48',\n",
       " '1120',\n",
       " '113',\n",
       " '1131',\n",
       " '114/14',\n",
       " '1146',\n",
       " '1151',\n",
       " '116',\n",
       " '1172',\n",
       " '118p',\n",
       " '11mths',\n",
       " '11pm',\n",
       " '12',\n",
       " '12,000',\n",
       " '1205',\n",
       " '120p',\n",
       " '121',\n",
       " '1225',\n",
       " '123',\n",
       " '125',\n",
       " '1250',\n",
       " '125gift',\n",
       " '128',\n",
       " '1282essexcm61xn',\n",
       " '12:30',\n",
       " '12hours',\n",
       " '12hrs',\n",
       " '12mths',\n",
       " '12n146tf15',\n",
       " '12n146tf150p',\n",
       " '13/10',\n",
       " '13/4',\n",
       " '130',\n",
       " '1327',\n",
       " '139',\n",
       " '140',\n",
       " '1405',\n",
       " '140ppm',\n",
       " '1450',\n",
       " '146tf150p',\n",
       " '14thmarch',\n",
       " '150',\n",
       " '1500',\n",
       " '150p',\n",
       " '150p16',\n",
       " '150pm',\n",
       " '150ppermesssubscription',\n",
       " '150ppm',\n",
       " '150ppmmobilesvary',\n",
       " '150ppmpobox10183bhamb64xe',\n",
       " '150ppmsg',\n",
       " '150ppmx3age16',\n",
       " '150pw',\n",
       " '150x3',\n",
       " '151',\n",
       " '1510',\n",
       " '15541',\n",
       " '15:26',\n",
       " '15h',\n",
       " '16',\n",
       " '16.150',\n",
       " '165',\n",
       " '1680',\n",
       " '16yrs',\n",
       " '177',\n",
       " '177hp51fl',\n",
       " '18',\n",
       " '18/11',\n",
       " '180',\n",
       " '1843',\n",
       " '1896wc1n3xx',\n",
       " '18:0430-',\n",
       " '18p',\n",
       " '18yrs',\n",
       " '1apple',\n",
       " '1b6a5ecef91ff9',\n",
       " '1cup',\n",
       " '1da',\n",
       " '1er',\n",
       " '1hr',\n",
       " '1im',\n",
       " '1lemon',\n",
       " '1million',\n",
       " '1more',\n",
       " '1n3xx',\n",
       " '1pm',\n",
       " '1st',\n",
       " '1st4terms',\n",
       " '1stchoice.co.uk',\n",
       " '1stone',\n",
       " '1thing',\n",
       " '1tulsi',\n",
       " '1win150ppmx3',\n",
       " '1win150ppmx3age16',\n",
       " '1win150ppmx3age16subscription',\n",
       " '1winaweek',\n",
       " '1winawk',\n",
       " '1x150p',\n",
       " '1yf',\n",
       " '2',\n",
       " '2,000',\n",
       " '2-4-',\n",
       " '2.15',\n",
       " '2.30',\n",
       " '2.50',\n",
       " '2.im',\n",
       " '2.naughty',\n",
       " '2/2',\n",
       " '2/3',\n",
       " '20',\n",
       " '20,000',\n",
       " '200',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '200p',\n",
       " '202',\n",
       " '20m12aq',\n",
       " '20p',\n",
       " '21',\n",
       " '21/11',\n",
       " '2187000',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '220cm2',\n",
       " '23',\n",
       " '2309',\n",
       " '23f',\n",
       " '23g',\n",
       " '24',\n",
       " '24/10',\n",
       " '24/7',\n",
       " '245c2150pm',\n",
       " '24hrs',\n",
       " '24m',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '250k',\n",
       " '255',\n",
       " '25p',\n",
       " '26.03',\n",
       " '26/10',\n",
       " '26/11',\n",
       " '2667',\n",
       " '26th',\n",
       " '27/03',\n",
       " '27/6',\n",
       " '28',\n",
       " '28/5',\n",
       " '28days',\n",
       " '28th',\n",
       " '28thfeb',\n",
       " '29',\n",
       " '29/03',\n",
       " '29/10',\n",
       " '2b',\n",
       " '2bed',\n",
       " '2bold',\n",
       " '2bremoved',\n",
       " '2c',\n",
       " '2channel',\n",
       " '2come',\n",
       " '2day',\n",
       " '2day.love',\n",
       " '2die',\n",
       " '2docd.please',\n",
       " '2end',\n",
       " '2exit',\n",
       " '2ez',\n",
       " '2find',\n",
       " '2getha',\n",
       " '2geva',\n",
       " '2go',\n",
       " '2go.did',\n",
       " '2gthr',\n",
       " '2hear',\n",
       " '2hook',\n",
       " '2hrs',\n",
       " '2i',\n",
       " '2kbsubject',\n",
       " '2marrow',\n",
       " '2mobile',\n",
       " '2moro',\n",
       " '2morow',\n",
       " '2morro',\n",
       " '2morrow',\n",
       " '2morrowxxxx',\n",
       " '2mro',\n",
       " '2mrw',\n",
       " '2mwen',\n",
       " '2nd',\n",
       " '2nhite',\n",
       " '2nights',\n",
       " '2nite',\n",
       " '2optout',\n",
       " '2p',\n",
       " '2px',\n",
       " '2rcv',\n",
       " '2stop',\n",
       " '2stoptx',\n",
       " '2stoptxt',\n",
       " '2tell',\n",
       " '2the',\n",
       " '2u',\n",
       " '2u2',\n",
       " '2watershd',\n",
       " '2waxsto',\n",
       " '2wks',\n",
       " '2worzels',\n",
       " '2wt',\n",
       " '2wu',\n",
       " '2years',\n",
       " '2yr',\n",
       " '2yrs',\n",
       " '3',\n",
       " '3.00',\n",
       " '3.75',\n",
       " '3.99',\n",
       " '3.sentiment',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300603',\n",
       " '300603t',\n",
       " '300p',\n",
       " '3030',\n",
       " '30apr',\n",
       " '30pp',\n",
       " '30s',\n",
       " '30th',\n",
       " '31',\n",
       " '31/10',\n",
       " '3100',\n",
       " '310303',\n",
       " '31p',\n",
       " '32',\n",
       " '32000',\n",
       " '3230',\n",
       " '32323',\n",
       " '326',\n",
       " '33.65',\n",
       " '330',\n",
       " '334',\n",
       " '334sk38ch',\n",
       " '3355',\n",
       " '33:50',\n",
       " '342/2',\n",
       " '350',\n",
       " '3510i',\n",
       " '35p',\n",
       " '3650',\n",
       " '36504',\n",
       " '36504w45wq',\n",
       " '365o4w45wq',\n",
       " '373',\n",
       " '3750',\n",
       " '37819',\n",
       " '38',\n",
       " '385',\n",
       " '391784',\n",
       " '39822',\n",
       " '3aj',\n",
       " '3cktz8r7',\n",
       " '3d',\n",
       " '3days',\n",
       " '3g',\n",
       " '3gbp',\n",
       " '3hrs',\n",
       " '3lions',\n",
       " '3lp',\n",
       " '3miles',\n",
       " '3mins',\n",
       " '3mobile',\n",
       " '3optical',\n",
       " '3pound',\n",
       " '3qxj9',\n",
       " '3rd',\n",
       " '3ss',\n",
       " '3uz',\n",
       " '3wks',\n",
       " '3x',\n",
       " '3xx',\n",
       " '4',\n",
       " '4-6',\n",
       " '4-7',\n",
       " '4.15',\n",
       " '4.30',\n",
       " '4.47',\n",
       " '4.49',\n",
       " '4.50',\n",
       " '4.cook',\n",
       " '4.rowdy',\n",
       " '40',\n",
       " '400',\n",
       " '400mins',\n",
       " '402',\n",
       " '403',\n",
       " '4041',\n",
       " '40411',\n",
       " '40533',\n",
       " '40gb',\n",
       " '40mph',\n",
       " '41',\n",
       " '41685',\n",
       " '41782',\n",
       " '420',\n",
       " '42049',\n",
       " '4217',\n",
       " '4235wc1n3xx',\n",
       " '42478',\n",
       " '42810',\n",
       " '4284',\n",
       " '42moro',\n",
       " '42wr29c',\n",
       " '430',\n",
       " '434',\n",
       " '434sk38wp150ppm18',\n",
       " '44',\n",
       " '440',\n",
       " '4403ldnw1a7rw18',\n",
       " '4477977060',\n",
       " '4478012592',\n",
       " '4487124040',\n",
       " '4490500003',\n",
       " '4490715124',\n",
       " '45',\n",
       " '450',\n",
       " '450p',\n",
       " '450ppw',\n",
       " '450pw',\n",
       " '45239',\n",
       " '45po139wa',\n",
       " '45w2tg150p',\n",
       " '47',\n",
       " '48',\n",
       " '4882',\n",
       " '48922',\n",
       " '49557',\n",
       " '4a',\n",
       " '4an18th',\n",
       " '4brekkie',\n",
       " '4d',\n",
       " '4eva',\n",
       " '4few',\n",
       " '4fil',\n",
       " '4get',\n",
       " '4get2text',\n",
       " '4give',\n",
       " '4got',\n",
       " '4goten',\n",
       " '4info',\n",
       " '4jx',\n",
       " '4msgs',\n",
       " '4mths',\n",
       " '4my',\n",
       " '4qf2',\n",
       " '4t',\n",
       " '4th',\n",
       " '4the',\n",
       " '4thnov.behind',\n",
       " '4txt',\n",
       " '4u',\n",
       " '4utxt',\n",
       " '4w',\n",
       " '4ward',\n",
       " '4wrd',\n",
       " '4xx26',\n",
       " '4years',\n",
       " '5',\n",
       " '5.00',\n",
       " '5.15',\n",
       " '5.30',\n",
       " '5.ful',\n",
       " '5.gardener',\n",
       " '5.terror',\n",
       " '5/9',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '5000.00',\n",
       " '50award',\n",
       " '50p',\n",
       " '50s',\n",
       " '5120',\n",
       " '515',\n",
       " '5226',\n",
       " '523',\n",
       " '5249',\n",
       " '526',\n",
       " '528',\n",
       " '530',\n",
       " '54',\n",
       " '545',\n",
       " '5digital',\n",
       " '5free',\n",
       " '5ish',\n",
       " '5k',\n",
       " '5min',\n",
       " '5mls',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5th',\n",
       " '5times',\n",
       " '5wb',\n",
       " '5we',\n",
       " '5wkg',\n",
       " '5wq',\n",
       " '5years',\n",
       " '6',\n",
       " '6.30',\n",
       " '6.45',\n",
       " '6.cruel',\n",
       " '6.house',\n",
       " '6.romantic',\n",
       " '60',\n",
       " '60,400',\n",
       " '600',\n",
       " '60p',\n",
       " '61',\n",
       " '61200',\n",
       " '61610',\n",
       " '62220cncl',\n",
       " '6230',\n",
       " '62468',\n",
       " '62735',\n",
       " '630',\n",
       " '63miles',\n",
       " '645',\n",
       " '65,61',\n",
       " '650',\n",
       " '66,382',\n",
       " '6600',\n",
       " '6650',\n",
       " '674',\n",
       " '6744123',\n",
       " '68866',\n",
       " '69',\n",
       " '69101',\n",
       " '69200',\n",
       " '69669',\n",
       " '69696',\n",
       " '69698',\n",
       " '69855',\n",
       " '69866.18',\n",
       " '69876',\n",
       " '69888',\n",
       " '69888nyt',\n",
       " '69911',\n",
       " '69969',\n",
       " '69988',\n",
       " '6days',\n",
       " '6gbp',\n",
       " '6hl',\n",
       " '6hrs',\n",
       " '6ish',\n",
       " '6missed',\n",
       " '6months',\n",
       " '6ph',\n",
       " '6pm',\n",
       " '6th',\n",
       " '6times',\n",
       " '6wu',\n",
       " '6zf',\n",
       " '7',\n",
       " '7.30',\n",
       " '7.8',\n",
       " '7.children',\n",
       " '7.romantic',\n",
       " '7.shy',\n",
       " '700',\n",
       " '71',\n",
       " '7250',\n",
       " '7250i',\n",
       " '730',\n",
       " '731',\n",
       " '734ls27yf',\n",
       " '74355',\n",
       " '75,000',\n",
       " '750',\n",
       " '7548',\n",
       " '75ldns7',\n",
       " '762',\n",
       " '7634',\n",
       " '7684',\n",
       " '77.11',\n",
       " '7732584351',\n",
       " '78',\n",
       " '786',\n",
       " '7876150',\n",
       " '79',\n",
       " '7:30',\n",
       " '7am',\n",
       " '7cfca1a',\n",
       " '7ish',\n",
       " '7oz',\n",
       " '7pm',\n",
       " '7th',\n",
       " '7ws',\n",
       " '7zs',\n",
       " '8',\n",
       " '8,22',\n",
       " '8-8',\n",
       " '8.30',\n",
       " '8.attractive',\n",
       " '8.lovable',\n",
       " '8.neighbour',\n",
       " '80',\n",
       " '800',\n",
       " '8000930705',\n",
       " '80062',\n",
       " '8007',\n",
       " '80082',\n",
       " '80086',\n",
       " '8012230',\n",
       " '80155',\n",
       " '80160',\n",
       " '80182',\n",
       " '8027',\n",
       " '80488',\n",
       " '80488.biz',\n",
       " '80608',\n",
       " '8077',\n",
       " '80878',\n",
       " '81010',\n",
       " '81151',\n",
       " '81303',\n",
       " '81618',\n",
       " '820554ad0a1705572711',\n",
       " '82228',\n",
       " '82242',\n",
       " '82277',\n",
       " '82277.unsub',\n",
       " '82324',\n",
       " '82468',\n",
       " '83021',\n",
       " '83039',\n",
       " '83049',\n",
       " '83110',\n",
       " '83118',\n",
       " '83222',\n",
       " '83332.please',\n",
       " '83338',\n",
       " '83355',\n",
       " '83370',\n",
       " '83383',\n",
       " '83435',\n",
       " '83600',\n",
       " '83738',\n",
       " '84',\n",
       " '84025',\n",
       " '84122',\n",
       " '84128',\n",
       " '84199',\n",
       " '84484',\n",
       " '85',\n",
       " '850',\n",
       " '85023',\n",
       " '85069',\n",
       " '85222',\n",
       " '85233',\n",
       " '8552',\n",
       " '85555',\n",
       " '86021',\n",
       " '861',\n",
       " '864233',\n",
       " '86688',\n",
       " '86888',\n",
       " '87021',\n",
       " '87066',\n",
       " '87070',\n",
       " '87077',\n",
       " '87121',\n",
       " '87131',\n",
       " '8714714',\n",
       " '87239',\n",
       " '87575',\n",
       " '8800',\n",
       " '88039',\n",
       " '88039.skilgme',\n",
       " '88066',\n",
       " '88088',\n",
       " '88222',\n",
       " '88600',\n",
       " '88800',\n",
       " '8883',\n",
       " '88877',\n",
       " '88888',\n",
       " '89',\n",
       " '89034',\n",
       " '89070',\n",
       " '89080',\n",
       " '89105',\n",
       " '89123',\n",
       " '89545',\n",
       " '89555',\n",
       " '89693',\n",
       " '89938',\n",
       " '8am',\n",
       " '8ball',\n",
       " '8i',\n",
       " '8lb',\n",
       " '8p',\n",
       " '8r',\n",
       " '8th',\n",
       " '8wp',\n",
       " '9',\n",
       " '9-6',\n",
       " '9.decent',\n",
       " '9.funny',\n",
       " '900',\n",
       " '9061100010',\n",
       " '910',\n",
       " '9280114',\n",
       " '92h',\n",
       " '930',\n",
       " '9307622',\n",
       " '945',\n",
       " '946',\n",
       " '95',\n",
       " '95qu',\n",
       " '97n7qp',\n",
       " '9832156',\n",
       " '9ae',\n",
       " ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(pca.components_, columns=terms, index=['topic{}'.format(i) for i in range(16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>#150</th>\n",
       "      <th>...</th>\n",
       "      <th>…</th>\n",
       "      <th>┾</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic0</th>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic2</th>\n",
       "      <td>0.071</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic3</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic4</th>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic5</th>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic6</th>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic7</th>\n",
       "      <td>0.158</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic8</th>\n",
       "      <td>0.337</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic9</th>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic10</th>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic11</th>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic12</th>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic13</th>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic14</th>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic15</th>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 9232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             !      \"      #   #150  ...      …      ┾    〨ud      鈥\n",
       "topic0  -0.071  0.008 -0.001 -0.000  ... -0.002  0.001  0.001  0.001\n",
       "topic1   0.063  0.008  0.000 -0.000  ...  0.003  0.001  0.001  0.001\n",
       "topic2   0.071  0.027  0.000  0.001  ...  0.002 -0.001 -0.001 -0.001\n",
       "topic3  -0.059 -0.032 -0.001 -0.000  ...  0.001  0.001  0.001  0.001\n",
       "topic4   0.380 -0.008  0.001  0.001  ...  0.002  0.001  0.001  0.001\n",
       "topic5  -0.266 -0.053  0.002  0.000  ... -0.003 -0.001 -0.001 -0.001\n",
       "topic6  -0.109  0.019 -0.001 -0.000  ... -0.001  0.000  0.000  0.000\n",
       "topic7   0.158  0.034  0.000 -0.000  ...  0.006 -0.000 -0.000 -0.000\n",
       "topic8   0.337  0.025 -0.002  0.000  ... -0.004  0.000  0.000  0.000\n",
       "topic9   0.086 -0.116 -0.000  0.000  ... -0.004 -0.000 -0.000 -0.000\n",
       "topic10 -0.295  0.003  0.001 -0.000  ... -0.004  0.000  0.000  0.000\n",
       "topic11  0.197 -0.005 -0.003 -0.000  ...  0.005 -0.000 -0.000 -0.000\n",
       "topic12  0.208 -0.018  0.001  0.000  ...  0.003 -0.000 -0.000 -0.000\n",
       "topic13 -0.065 -0.027  0.004 -0.000  ...  0.000  0.001  0.001  0.001\n",
       "topic14 -0.019 -0.011  0.001  0.001  ... -0.005  0.001  0.001  0.001\n",
       "topic15  0.021 -0.021  0.000 -0.001  ... -0.001 -0.000 -0.000 -0.000\n",
       "\n",
       "[16 rows x 9232 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 8\n",
    "weights.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>;)</th>\n",
       "      <th>:)</th>\n",
       "      <th>half</th>\n",
       "      <th>off</th>\n",
       "      <th>free</th>\n",
       "      <th>crazy</th>\n",
       "      <th>deal</th>\n",
       "      <th>only</th>\n",
       "      <th>$</th>\n",
       "      <th>80</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic0</th>\n",
       "      <td>-7.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic2</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic3</th>\n",
       "      <td>-5.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic4</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-12.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic5</th>\n",
       "      <td>-26.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic6</th>\n",
       "      <td>-10.9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>19.8</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic7</th>\n",
       "      <td>15.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic8</th>\n",
       "      <td>33.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic9</th>\n",
       "      <td>8.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic10</th>\n",
       "      <td>-29.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic11</th>\n",
       "      <td>19.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic12</th>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic13</th>\n",
       "      <td>-6.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>40.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic14</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic15</th>\n",
       "      <td>2.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            !   ;)    :)  half  off  free  crazy  deal  only    $   80    %\n",
       "topic0   -7.1  0.1  -0.5  -0.0 -0.4  -2.0   -0.0  -0.1  -2.2  0.3 -0.0 -0.0\n",
       "topic1    6.3  0.0   7.4   0.1  0.4  -2.3   -0.2  -0.1  -3.8 -0.1 -0.0 -0.2\n",
       "topic2    7.1  0.2  -0.1   0.0  0.3   4.4    0.1  -0.1   0.7  0.0  0.0  0.1\n",
       "topic3   -5.9 -0.3  -7.0   0.2  0.3  -0.2    0.0   0.1  -2.3  0.1 -0.1 -0.3\n",
       "topic4   38.0 -0.1 -12.4  -0.1 -0.2   9.9    0.1  -0.2   3.0  0.3  0.1 -0.1\n",
       "topic5  -26.6  0.1  -1.6  -0.3 -0.7  -1.4   -0.6  -0.2  -1.8 -0.9  0.0  0.0\n",
       "topic6  -10.9 -0.5  19.8  -0.4 -0.9  -0.6   -0.2  -0.1  -1.4 -0.0 -0.0 -0.1\n",
       "topic7   15.8  0.1 -17.7   0.8  0.8  -2.9    0.0   0.1  -1.9 -0.3  0.0 -0.1\n",
       "topic8   33.7  0.1   5.0  -0.4 -0.5   0.2   -0.5  -0.4   3.2 -0.6 -0.0 -0.2\n",
       "topic9    8.6 -0.3  16.8   1.4 -0.9   6.2   -0.4  -0.4   2.9 -0.4 -0.0  0.0\n",
       "topic10 -29.5 -0.2 -10.6   0.1  0.1  12.9    0.2   0.0   0.2 -0.1 -0.0 -0.2\n",
       "topic11  19.7  0.4  36.2   0.5  1.3  -4.4    0.1   0.1   0.4 -0.4  0.0 -0.3\n",
       "topic12  20.8  0.0  -2.2  -0.1  0.3   5.2    0.5  -0.0  -3.8 -0.3 -0.0 -0.3\n",
       "topic13  -6.5 -0.4  40.7  -0.3  0.7   2.8   -0.1   0.1   0.7 -0.2  0.0 -0.1\n",
       "topic14  -1.9 -0.1  18.5  -0.2 -0.7   6.4    0.1  -0.1   3.4  0.1  0.0 -0.3\n",
       "topic15   2.1 -0.6   1.7  -0.3 -1.4  -1.8   -0.7   0.5   2.2 -0.4  0.1 -0.1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 12\n",
    "deals = weights['! ;) :) half off free crazy deal only $ 80 %'.split()].round(3) * 100\n",
    "deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic0    -11.9\n",
       "topic1      7.5\n",
       "topic2     12.7\n",
       "topic3    -15.4\n",
       "topic4     38.3\n",
       "topic5    -34.0\n",
       "topic6      4.7\n",
       "topic7     -5.3\n",
       "topic8     39.6\n",
       "topic9     33.5\n",
       "topic10   -27.1\n",
       "topic11    53.6\n",
       "topic12    20.1\n",
       "topic13    37.4\n",
       "topic14    25.2\n",
       "topic15     1.3\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deals.T.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.4 Using truncated SVD for SMS message semantic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=16, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).toarray()\n",
    "tfidf_docs = pd.DataFrame(tfidf_docs)\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_topic_vectors = svd.fit_transform(tfidf_docs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns, index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>...</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  ...  topic10  topic11  topic12  topic13  topic14  topic15\n",
       "sms0    0.201   0.003   0.037   0.011  -0.019  -0.053  ...    0.007   -0.007    0.002   -0.036   -0.014    0.037\n",
       "sms1    0.404  -0.094  -0.078   0.051   0.100   0.047  ...   -0.004    0.036    0.043   -0.021    0.051   -0.042\n",
       "sms2!  -0.030  -0.048   0.090  -0.067   0.091  -0.043  ...    0.125    0.023    0.026   -0.020   -0.042    0.052\n",
       "sms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  ...    0.022    0.023    0.073   -0.046    0.022   -0.070\n",
       "sms4    0.002   0.031   0.038   0.034  -0.075  -0.093  ...    0.028   -0.009    0.027    0.034   -0.083   -0.021\n",
       "sms5!  -0.016   0.059   0.014  -0.006   0.122  -0.040  ...    0.041    0.055   -0.037    0.075   -0.001    0.020\n",
       "\n",
       "[6 rows x 16 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.5 How well does LSA work for spam classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_topic_vectors = (svd_topic_vectors.T / np.linalg.norm(svd_topic_vectors, axis=1)).T  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms0</th>\n",
       "      <th>sms1</th>\n",
       "      <th>sms2!</th>\n",
       "      <th>sms3</th>\n",
       "      <th>sms4</th>\n",
       "      <th>sms5!</th>\n",
       "      <th>sms6</th>\n",
       "      <th>sms7</th>\n",
       "      <th>sms8!</th>\n",
       "      <th>sms9!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms6</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms7</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms8!</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms9!</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sms0  sms1  sms2!  sms3  sms4  sms5!  sms6  sms7  sms8!  sms9!\n",
       "sms0    1.0   0.6   -0.1   0.6  -0.0   -0.3  -0.3  -0.1   -0.3   -0.3\n",
       "sms1    0.6   1.0   -0.2   0.8  -0.2    0.0  -0.2  -0.2   -0.1   -0.1\n",
       "sms2!  -0.1  -0.2    1.0  -0.2   0.1    0.4   0.0   0.3    0.5    0.4\n",
       "sms3    0.6   0.8   -0.2   1.0  -0.2   -0.3  -0.1  -0.3   -0.2   -0.1\n",
       "sms4   -0.0  -0.2    0.1  -0.2   1.0    0.2   0.0   0.1   -0.4   -0.2\n",
       "sms5!  -0.3   0.0    0.4  -0.3   0.2    1.0  -0.1   0.1    0.3    0.4\n",
       "sms6   -0.3  -0.2    0.0  -0.1   0.0   -0.1   1.0   0.1   -0.2   -0.2\n",
       "sms7   -0.1  -0.2    0.3  -0.3   0.1    0.1   0.1   1.0    0.1    0.4\n",
       "sms8!  -0.3  -0.1    0.5  -0.2  -0.4    0.3  -0.2   0.1    1.0    0.3\n",
       "sms9!  -0.3  -0.1    0.4  -0.1  -0.2    0.4  -0.2   0.4    0.3    1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_topic_vectors.iloc[:10].dot(svd_topic_vectors.iloc[:10].T).round(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Latent Dirichlet allocation (LDiA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam                                               text\n",
       "sms0      0  Go until jurong point, crazy.. Available only ...\n",
       "sms1      0                      Ok lar... Joking wif u oni...\n",
       "sms2!     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "sms3      0  U dun say so early hor... U c already then say...\n",
       "sms4      0  Nah I don't think he goes to usf, he lives aro...\n",
       "sms5!     1  FreeMsg Hey there darling it's been 3 week's n..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103260\n"
     ]
    }
   ],
   "source": [
    "total_corpus_len = 0\n",
    "for document_text in sms.text:\n",
    "    total_corpus_len += len(casual_tokenize(document_text))\n",
    "print(total_corpus_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.35"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_document_len = total_corpus_len / len(sms)\n",
    "round(mean_document_len, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.34794293983874"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or, in a one-liner\n",
    "sum([len(casual_tokenize(t)) for t in sms.text]) * 1. / len(sms.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=sms.text).toarray(), index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>9226</th>\n",
       "      <th>9227</th>\n",
       "      <th>9228</th>\n",
       "      <th>9229</th>\n",
       "      <th>9230</th>\n",
       "      <th>9231</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4832!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4837 rows × 9232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     ...  9226  9227  9228  9229  9230  9231\n",
       "sms0         0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "sms1         0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "sms2!        0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "sms3         0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "sms4         0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "...        ...   ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...\n",
       "sms4832!     1     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "sms4833      0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "sms4834      0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "sms4835      0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "sms4836      0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
       "\n",
       "[4837 rows x 9232 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>#150</th>\n",
       "      <th>#5000</th>\n",
       "      <th>$</th>\n",
       "      <th>...</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>…</th>\n",
       "      <th>┾</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4832!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4837 rows × 9232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          !  \"  #  #150  #5000  $  ...  ’  “  …  ┾  〨ud  鈥\n",
       "sms0      0  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "sms1      0  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "sms2!     0  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "sms3      0  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "sms4      0  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "...      .. .. ..   ...    ... ..  ... .. .. .. ..  ... ..\n",
       "sms4832!  1  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "sms4833   0  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "sms4834   0  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "sms4835   0  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "sms4836   0  0  0     0      0  0  ...  0  0  0  0    0  0\n",
       "\n",
       "[4837 rows x 9232 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(),counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms\n",
    "bow_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.loc['sms0'].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",            1\n",
       "..           1\n",
       "...          2\n",
       "amore        1\n",
       "available    1\n",
       "buffet       1\n",
       "bugis        1\n",
       "cine         1\n",
       "crazy        1\n",
       "e            1\n",
       "go           1\n",
       "got          1\n",
       "great        1\n",
       "in           1\n",
       "jurong       1\n",
       "la           1\n",
       "n            1\n",
       "only         1\n",
       "point        1\n",
       "there        1\n",
       "until        1\n",
       "wat          1\n",
       "world        1\n",
       "Name: sms0, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_docs.loc['sms0'][bow_docs.loc['sms0'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "ldia = LDiA(n_components=16, learning_method='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldia = ldia.fit(bow_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 9232)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>...</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>20.03</td>\n",
       "      <td>20.44</td>\n",
       "      <td>0.85</td>\n",
       "      <td>52.68</td>\n",
       "      <td>0.06</td>\n",
       "      <td>204.72</td>\n",
       "      <td>...</td>\n",
       "      <td>134.04</td>\n",
       "      <td>38.21</td>\n",
       "      <td>100.30</td>\n",
       "      <td>135.82</td>\n",
       "      <td>481.08</td>\n",
       "      <td>5.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>0.06</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>92.34</td>\n",
       "      <td>24.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#150</th>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#5000</th>\n",
       "      <td>3.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  ...  topic10  \\\n",
       "!       20.03   20.44    0.85   52.68    0.06  204.72  ...   134.04   \n",
       "\"        0.06    9.00    0.06    0.06    0.12    0.06  ...     3.80   \n",
       "#        0.06    0.06    0.06    0.06    0.06    0.06  ...     0.06   \n",
       "#150     0.06    1.06    0.06    0.06    0.06    0.06  ...     0.06   \n",
       "#5000    3.06    0.06    0.06    0.06    0.06    0.06  ...     0.06   \n",
       "\n",
       "       topic11  topic12  topic13  topic14  topic15  \n",
       "!        38.21   100.30   135.82   481.08     5.19  \n",
       "\"         0.06     7.41     0.06    92.34    24.30  \n",
       "#         0.06     0.06     0.06     5.06     0.06  \n",
       "#150      0.06     0.06     0.06     0.06     0.06  \n",
       "#5000     0.06     0.06     0.06     0.06     0.06  \n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.width', 75)\n",
    "components = pd.DataFrame(ldia.components_.T, index=terms, columns=columns)\n",
    "components.round(2).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to      174.492758\n",
       "the     132.447021\n",
       "and     103.139835\n",
       ".        95.918658\n",
       "your     64.338532\n",
       "from     62.993171\n",
       "for      59.914714\n",
       "of       59.226303\n",
       "free     59.122778\n",
       "call     55.558074\n",
       "Name: topic3, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components.topic3.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldia16_topic_vectors = ldia.transform(bow_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4837, 16)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia16_topic_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors, index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>...</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.444411</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.139232</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.198444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.664294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.313831</td>\n",
       "      <td>0.001563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.088968</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.696919</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.244747</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4832!</th>\n",
       "      <td>0.209387</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.168072</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.420592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4833</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.354954</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4834</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4835</th>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.446139</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.240159</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4836</th>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4837 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic0    topic1    topic2    topic3    topic4    topic5  \\\n",
       "sms0      0.002500  0.002500  0.002500  0.002500  0.002500  0.002500   \n",
       "sms1      0.006944  0.006944  0.006944  0.006944  0.139232  0.006944   \n",
       "sms2!     0.001563  0.001563  0.001563  0.001563  0.001563  0.664294   \n",
       "sms3      0.004464  0.004464  0.004464  0.004464  0.004464  0.004464   \n",
       "sms4      0.004167  0.004167  0.004167  0.004167  0.696919  0.004167   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "sms4832!  0.209387  0.001563  0.001563  0.001563  0.001563  0.183200   \n",
       "sms4833   0.006250  0.006250  0.354954  0.006250  0.006250  0.006250   \n",
       "sms4834   0.003906  0.003906  0.003906  0.003906  0.003906  0.003906   \n",
       "sms4835   0.002315  0.002315  0.002315  0.446139  0.002315  0.002315   \n",
       "sms4836   0.007813  0.007813  0.007813  0.882812  0.007813  0.007813   \n",
       "\n",
       "          ...   topic10   topic11   topic12   topic13   topic14   topic15  \n",
       "sms0      ...  0.002500  0.002500  0.444411  0.002500  0.002500  0.002500  \n",
       "sms1      ...  0.006944  0.006944  0.006944  0.006944  0.006944  0.198444  \n",
       "sms2!     ...  0.001563  0.001563  0.001563  0.001563  0.313831  0.001563  \n",
       "sms3      ...  0.004464  0.004464  0.088968  0.004464  0.004464  0.004464  \n",
       "sms4      ...  0.004167  0.004167  0.004167  0.004167  0.244747  0.004167  \n",
       "...       ...       ...       ...       ...       ...       ...       ...  \n",
       "sms4832!  ...  0.001563  0.001563  0.168072  0.001563  0.001563  0.420592  \n",
       "sms4833   ...  0.006250  0.006250  0.006250  0.006250  0.006250  0.006250  \n",
       "sms4834   ...  0.003906  0.003906  0.003906  0.003906  0.941406  0.003906  \n",
       "sms4835   ...  0.002315  0.240159  0.002315  0.002315  0.002315  0.002315  \n",
       "sms4836   ...  0.007813  0.007813  0.007813  0.007813  0.007813  0.007813  \n",
       "\n",
       "[4837 rows x 16 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia16_topic_vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.3 LDiA + LDA = spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ldia16_topic_vectors, sms.spam, test_size=0.5, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "sms['ldia16_spam'] = lda.predict(ldia16_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.620075</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.344925</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.781721</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.121056</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.088350</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.849150</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.394632</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.333172</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.136218</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.085978</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4832!</th>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.927395</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.050730</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4833</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.589556</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.322944</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4834</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.494008</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.354560</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.100650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4835</th>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.681962</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.285630</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4836</th>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4837 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5   \\\n",
       "sms0      0.002500  0.620075  0.002500  0.002500  0.002500  0.002500   \n",
       "sms1      0.006944  0.006944  0.006944  0.006944  0.006944  0.006944   \n",
       "sms2!     0.001563  0.001563  0.001563  0.001563  0.001563  0.001563   \n",
       "sms3      0.004464  0.004464  0.004464  0.004464  0.088350  0.004464   \n",
       "sms4      0.394632  0.004167  0.333172  0.004167  0.004167  0.004167   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "sms4832!  0.001563  0.001563  0.001563  0.927395  0.001563  0.001563   \n",
       "sms4833   0.006250  0.006250  0.006250  0.006250  0.006250  0.589556   \n",
       "sms4834   0.003906  0.003906  0.494008  0.003906  0.003906  0.003906   \n",
       "sms4835   0.002315  0.002315  0.681962  0.002315  0.002315  0.002315   \n",
       "sms4836   0.007813  0.007813  0.007813  0.007813  0.007813  0.007813   \n",
       "\n",
       "                6         7         8         9         10        11  \\\n",
       "sms0      0.002500  0.002500  0.344925  0.002500  0.002500  0.002500   \n",
       "sms1      0.006944  0.006944  0.781721  0.006944  0.006944  0.121056   \n",
       "sms2!     0.001563  0.001563  0.001563  0.976562  0.001563  0.001563   \n",
       "sms3      0.004464  0.004464  0.849150  0.004464  0.004464  0.004464   \n",
       "sms4      0.136218  0.004167  0.004167  0.004167  0.004167  0.004167   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "sms4832!  0.001563  0.001563  0.001563  0.050730  0.001563  0.001563   \n",
       "sms4833   0.006250  0.006250  0.322944  0.006250  0.006250  0.006250   \n",
       "sms4834   0.003906  0.003906  0.354560  0.003906  0.003906  0.003906   \n",
       "sms4835   0.002315  0.002315  0.002315  0.285630  0.002315  0.002315   \n",
       "sms4836   0.007813  0.007813  0.007813  0.007813  0.882812  0.007813   \n",
       "\n",
       "                12        13        14        15  \n",
       "sms0      0.002500  0.002500  0.002500  0.002500  \n",
       "sms1      0.006944  0.006944  0.006944  0.006944  \n",
       "sms2!     0.001563  0.001563  0.001563  0.001563  \n",
       "sms3      0.004464  0.004464  0.004464  0.004464  \n",
       "sms4      0.085978  0.004167  0.004167  0.004167  \n",
       "...            ...       ...       ...       ...  \n",
       "sms4832!  0.001563  0.001563  0.001563  0.001563  \n",
       "sms4833   0.006250  0.006250  0.006250  0.006250  \n",
       "sms4834   0.003906  0.003906  0.003906  0.100650  \n",
       "sms4835   0.002315  0.002315  0.002315  0.002315  \n",
       "sms4836   0.007813  0.007813  0.007813  0.007813  \n",
       "\n",
       "[4837 rows x 16 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia16_topic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.748\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).toarray()\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean(axis=0) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_docs, sms.spam.values, test_size=0.5, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "print(round(float(lda.score(X_train, y_train)), 3))\n",
    "print(round(float(lda.score(X_test, y_test)), 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5.4 A fairer comparison: 32 LDiA topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 9232)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32 = LDiA(n_components=32, learning_method='batch')\n",
    "ldia32 = ldia32.fit(bow_docs)\n",
    "ldia32.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>...</th>\n",
       "      <th>topic26</th>\n",
       "      <th>topic27</th>\n",
       "      <th>topic28</th>\n",
       "      <th>topic29</th>\n",
       "      <th>topic30</th>\n",
       "      <th>topic31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  ...  topic26  \\\n",
       "sms0      0.0    0.00    0.00     0.0     0.0     0.0  ...      0.0   \n",
       "sms1      0.0    0.89    0.00     0.0     0.0     0.0  ...      0.0   \n",
       "sms2!     0.0    0.00    0.00     0.0     0.0     0.0  ...      0.0   \n",
       "sms3      0.0    0.00    0.00     0.0     0.0     0.0  ...      0.0   \n",
       "sms4      0.0    0.00    0.34     0.0     0.0     0.0  ...      0.0   \n",
       "\n",
       "       topic27  topic28  topic29  topic30  topic31  \n",
       "sms0       0.0      0.0      0.0      0.0      0.0  \n",
       "sms1       0.0      0.0      0.0      0.0      0.0  \n",
       "sms2!      0.0      0.0      0.0      0.0      0.0  \n",
       "sms3       0.0      0.0      0.0      0.0      0.0  \n",
       "sms4       0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32_topic_vectors = ldia32.transform(bow_docs)\n",
    "columns32 = ['topic{}'.format(i) for i in range(ldia32.n_components)]\n",
    "ldia32_topic_vectors = pd.DataFrame(ldia32_topic_vectors, index=index, columns=columns32)\n",
    "ldia32_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ldia32_topic_vectors, sms.spam, test_size=0.5, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "sms['ldia32_spam'] = lda.predict(ldia32_topic_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2418, 32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(lda.score(X_train, y_train)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/anaconda3/lib/python3.9/site-packages/sklearn/__init__.py'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpriors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstore_covariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0m_ClassNamePrefixFeaturesOutMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mLinearClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Linear Discriminant Analysis.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    A classifier with a linear decision boundary, generated by fitting class\u001b[0m\n",
      "\u001b[0;34m    conditional densities to the data and using Bayes' rule.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The model fits a Gaussian density to each class, assuming that all classes\u001b[0m\n",
      "\u001b[0;34m    share the same covariance matrix.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The fitted model can also be used to reduce the dimensionality of the input\u001b[0m\n",
      "\u001b[0;34m    by projecting it to the most discriminative directions, using the\u001b[0m\n",
      "\u001b[0;34m    `transform` method.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. versionadded:: 0.17\u001b[0m\n",
      "\u001b[0;34m       *LinearDiscriminantAnalysis*.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Read more in the :ref:`User Guide <lda_qda>`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Parameters\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m    solver : {'svd', 'lsqr', 'eigen'}, default='svd'\u001b[0m\n",
      "\u001b[0;34m        Solver to use, possible values:\u001b[0m\n",
      "\u001b[0;34m          - 'svd': Singular value decomposition (default).\u001b[0m\n",
      "\u001b[0;34m            Does not compute the covariance matrix, therefore this solver is\u001b[0m\n",
      "\u001b[0;34m            recommended for data with a large number of features.\u001b[0m\n",
      "\u001b[0;34m          - 'lsqr': Least squares solution.\u001b[0m\n",
      "\u001b[0;34m            Can be combined with shrinkage or custom covariance estimator.\u001b[0m\n",
      "\u001b[0;34m          - 'eigen': Eigenvalue decomposition.\u001b[0m\n",
      "\u001b[0;34m            Can be combined with shrinkage or custom covariance estimator.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    shrinkage : 'auto' or float, default=None\u001b[0m\n",
      "\u001b[0;34m        Shrinkage parameter, possible values:\u001b[0m\n",
      "\u001b[0;34m          - None: no shrinkage (default).\u001b[0m\n",
      "\u001b[0;34m          - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.\u001b[0m\n",
      "\u001b[0;34m          - float between 0 and 1: fixed shrinkage parameter.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        This should be left to None if `covariance_estimator` is used.\u001b[0m\n",
      "\u001b[0;34m        Note that shrinkage works only with 'lsqr' and 'eigen' solvers.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    priors : array-like of shape (n_classes,), default=None\u001b[0m\n",
      "\u001b[0;34m        The class prior probabilities. By default, the class proportions are\u001b[0m\n",
      "\u001b[0;34m        inferred from the training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    n_components : int, default=None\u001b[0m\n",
      "\u001b[0;34m        Number of components (<= min(n_classes - 1, n_features)) for\u001b[0m\n",
      "\u001b[0;34m        dimensionality reduction. If None, will be set to\u001b[0m\n",
      "\u001b[0;34m        min(n_classes - 1, n_features). This parameter only affects the\u001b[0m\n",
      "\u001b[0;34m        `transform` method.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    store_covariance : bool, default=False\u001b[0m\n",
      "\u001b[0;34m        If True, explicitly compute the weighted within-class covariance\u001b[0m\n",
      "\u001b[0;34m        matrix when solver is 'svd'. The matrix is always computed\u001b[0m\n",
      "\u001b[0;34m        and stored for the other solvers.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.17\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    tol : float, default=1.0e-4\u001b[0m\n",
      "\u001b[0;34m        Absolute threshold for a singular value of X to be considered\u001b[0m\n",
      "\u001b[0;34m        significant, used to estimate the rank of X. Dimensions whose\u001b[0m\n",
      "\u001b[0;34m        singular values are non-significant are discarded. Only used if\u001b[0m\n",
      "\u001b[0;34m        solver is 'svd'.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.17\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    covariance_estimator : covariance estimator, default=None\u001b[0m\n",
      "\u001b[0;34m        If not None, `covariance_estimator` is used to estimate\u001b[0m\n",
      "\u001b[0;34m        the covariance matrices instead of relying on the empirical\u001b[0m\n",
      "\u001b[0;34m        covariance estimator (with potential shrinkage).\u001b[0m\n",
      "\u001b[0;34m        The object should have a fit method and a ``covariance_`` attribute\u001b[0m\n",
      "\u001b[0;34m        like the estimators in :mod:`sklearn.covariance`.\u001b[0m\n",
      "\u001b[0;34m        if None the shrinkage parameter drives the estimate.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        This should be left to None if `shrinkage` is used.\u001b[0m\n",
      "\u001b[0;34m        Note that `covariance_estimator` works only with 'lsqr' and 'eigen'\u001b[0m\n",
      "\u001b[0;34m        solvers.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.24\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Attributes\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m    coef_ : ndarray of shape (n_features,) or (n_classes, n_features)\u001b[0m\n",
      "\u001b[0;34m        Weight vector(s).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    intercept_ : ndarray of shape (n_classes,)\u001b[0m\n",
      "\u001b[0;34m        Intercept term.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    covariance_ : array-like of shape (n_features, n_features)\u001b[0m\n",
      "\u001b[0;34m        Weighted within-class covariance matrix. It corresponds to\u001b[0m\n",
      "\u001b[0;34m        `sum_k prior_k * C_k` where `C_k` is the covariance matrix of the\u001b[0m\n",
      "\u001b[0;34m        samples in class `k`. The `C_k` are estimated using the (potentially\u001b[0m\n",
      "\u001b[0;34m        shrunk) biased estimator of covariance. If solver is 'svd', only\u001b[0m\n",
      "\u001b[0;34m        exists when `store_covariance` is True.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    explained_variance_ratio_ : ndarray of shape (n_components,)\u001b[0m\n",
      "\u001b[0;34m        Percentage of variance explained by each of the selected components.\u001b[0m\n",
      "\u001b[0;34m        If ``n_components`` is not set then all components are stored and the\u001b[0m\n",
      "\u001b[0;34m        sum of explained variances is equal to 1.0. Only available when eigen\u001b[0m\n",
      "\u001b[0;34m        or svd solver is used.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    means_ : array-like of shape (n_classes, n_features)\u001b[0m\n",
      "\u001b[0;34m        Class-wise means.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    priors_ : array-like of shape (n_classes,)\u001b[0m\n",
      "\u001b[0;34m        Class priors (sum to 1).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    scalings_ : array-like of shape (rank, n_classes - 1)\u001b[0m\n",
      "\u001b[0;34m        Scaling of the features in the space spanned by the class centroids.\u001b[0m\n",
      "\u001b[0;34m        Only available for 'svd' and 'eigen' solvers.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    xbar_ : array-like of shape (n_features,)\u001b[0m\n",
      "\u001b[0;34m        Overall mean. Only present if solver is 'svd'.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    classes_ : array-like of shape (n_classes,)\u001b[0m\n",
      "\u001b[0;34m        Unique class labels.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    n_features_in_ : int\u001b[0m\n",
      "\u001b[0;34m        Number of features seen during :term:`fit`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.24\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    feature_names_in_ : ndarray of shape (`n_features_in_`,)\u001b[0m\n",
      "\u001b[0;34m        Names of features seen during :term:`fit`. Defined only when `X`\u001b[0m\n",
      "\u001b[0;34m        has feature names that are all strings.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 1.0\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    See Also\u001b[0m\n",
      "\u001b[0;34m    --------\u001b[0m\n",
      "\u001b[0;34m    QuadraticDiscriminantAnalysis : Quadratic Discriminant Analysis.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Examples\u001b[0m\n",
      "\u001b[0;34m    --------\u001b[0m\n",
      "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
      "\u001b[0;34m    >>> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\u001b[0m\n",
      "\u001b[0;34m    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\u001b[0m\n",
      "\u001b[0;34m    >>> y = np.array([1, 1, 1, 2, 2, 2])\u001b[0m\n",
      "\u001b[0;34m    >>> clf = LinearDiscriminantAnalysis()\u001b[0m\n",
      "\u001b[0;34m    >>> clf.fit(X, y)\u001b[0m\n",
      "\u001b[0;34m    LinearDiscriminantAnalysis()\u001b[0m\n",
      "\u001b[0;34m    >>> print(clf.predict([[-0.8, -1]]))\u001b[0m\n",
      "\u001b[0;34m    [1]\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"svd\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpriors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstore_covariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_covariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore_covariance\u001b[0m  \u001b[0;31m# used only in svd solver\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtol\u001b[0m  \u001b[0;31m# used only in svd solver\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_solve_lsqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Least squares solver.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        The least squares solver computes a straightforward solution of the\u001b[0m\n",
      "\u001b[0;34m        optimal decision rule based directly on the discriminant functions. It\u001b[0m\n",
      "\u001b[0;34m        can only be used for classification (with any covariance estimator),\u001b[0m\n",
      "\u001b[0;34m        because\u001b[0m\n",
      "\u001b[0;34m        estimation of eigenvectors is not performed. Therefore, dimensionality\u001b[0m\n",
      "\u001b[0;34m        reduction with the transform is not supported.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        y : array-like of shape (n_samples,) or (n_samples, n_classes)\u001b[0m\n",
      "\u001b[0;34m            Target values.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        shrinkage : 'auto', float or None\u001b[0m\n",
      "\u001b[0;34m            Shrinkage parameter, possible values:\u001b[0m\n",
      "\u001b[0;34m              - None: no shrinkage.\u001b[0m\n",
      "\u001b[0;34m              - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.\u001b[0m\n",
      "\u001b[0;34m              - float between 0 and 1: fixed shrinkage parameter.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            Shrinkage parameter is ignored if  `covariance_estimator` i\u001b[0m\n",
      "\u001b[0;34m            not None\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        covariance_estimator : estimator, default=None\u001b[0m\n",
      "\u001b[0;34m            If not None, `covariance_estimator` is used to estimate\u001b[0m\n",
      "\u001b[0;34m            the covariance matrices instead of relying the empirical\u001b[0m\n",
      "\u001b[0;34m            covariance estimator (with potential shrinkage).\u001b[0m\n",
      "\u001b[0;34m            The object should have a fit method and a ``covariance_`` attribute\u001b[0m\n",
      "\u001b[0;34m            like the estimators in sklearn.covariance.\u001b[0m\n",
      "\u001b[0;34m            if None the shrinkage parameter drives the estimate.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            .. versionadded:: 0.24\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Notes\u001b[0m\n",
      "\u001b[0;34m        -----\u001b[0m\n",
      "\u001b[0;34m        This solver is based on [1]_, section 2.6.2, pp. 39-41.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        References\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        .. [1] R. O. Duda, P. E. Hart, D. G. Stork. Pattern Classification\u001b[0m\n",
      "\u001b[0;34m           (Second Edition). John Wiley & Sons, Inc., New York, 2001. ISBN\u001b[0m\n",
      "\u001b[0;34m           0-471-05669-3.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_solve_eigen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Eigenvalue solver.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        The eigenvalue solver computes the optimal solution of the Rayleigh\u001b[0m\n",
      "\u001b[0;34m        coefficient (basically the ratio of between class scatter to within\u001b[0m\n",
      "\u001b[0;34m        class scatter). This solver supports both classification and\u001b[0m\n",
      "\u001b[0;34m        dimensionality reduction (with any covariance estimator).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        y : array-like of shape (n_samples,) or (n_samples, n_targets)\u001b[0m\n",
      "\u001b[0;34m            Target values.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        shrinkage : 'auto', float or None\u001b[0m\n",
      "\u001b[0;34m            Shrinkage parameter, possible values:\u001b[0m\n",
      "\u001b[0;34m              - None: no shrinkage.\u001b[0m\n",
      "\u001b[0;34m              - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.\u001b[0m\n",
      "\u001b[0;34m              - float between 0 and 1: fixed shrinkage constant.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            Shrinkage parameter is ignored if  `covariance_estimator` i\u001b[0m\n",
      "\u001b[0;34m            not None\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        covariance_estimator : estimator, default=None\u001b[0m\n",
      "\u001b[0;34m            If not None, `covariance_estimator` is used to estimate\u001b[0m\n",
      "\u001b[0;34m            the covariance matrices instead of relying the empirical\u001b[0m\n",
      "\u001b[0;34m            covariance estimator (with potential shrinkage).\u001b[0m\n",
      "\u001b[0;34m            The object should have a fit method and a ``covariance_`` attribute\u001b[0m\n",
      "\u001b[0;34m            like the estimators in sklearn.covariance.\u001b[0m\n",
      "\u001b[0;34m            if None the shrinkage parameter drives the estimate.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            .. versionadded:: 0.24\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Notes\u001b[0m\n",
      "\u001b[0;34m        -----\u001b[0m\n",
      "\u001b[0;34m        This solver is based on [1]_, section 3.8.3, pp. 121-124.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        References\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        .. [1] R. O. Duda, P. E. Hart, D. G. Stork. Pattern Classification\u001b[0m\n",
      "\u001b[0;34m           (Second Edition). John Wiley & Sons, Inc., New York, 2001. ISBN\u001b[0m\n",
      "\u001b[0;34m           0-471-05669-3.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mSw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m  \u001b[0;31m# within scatter\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mSt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# total scatter\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mSb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mSw\u001b[0m  \u001b[0;31m# between scatter\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mevecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# sort eigenvectors\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevecs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_solve_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"SVD solver.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        y : array-like of shape (n_samples,) or (n_samples, n_targets)\u001b[0m\n",
      "\u001b[0;34m            Target values.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_covariance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mXc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mXg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mXc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mXc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# 1) within (univariate) scaling by with classes std-dev\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# avoid division by zero in normalization\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# 2) Within variance scaling\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# SVD of centered (within)scaled data\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Scaling of within covariance is: V' 1/S\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscalings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# 3) Between variance scaling\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Scale weighted centers\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mscalings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Centers are living in a space with n_classes-1 dim (maximum)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Use SVD to find projection in the space spanned by the\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# (n_classes) centers\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Fit the Linear Discriminant Analysis model.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m           .. versionchanged:: 0.19\u001b[0m\n",
      "\u001b[0;34m              *store_covariance* has been moved to main constructor.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m           .. versionchanged:: 0.19\u001b[0m\n",
      "\u001b[0;34m              *tol* has been moved to main constructor.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        y : array-like of shape (n_samples,)\u001b[0m\n",
      "\u001b[0;34m            Target values.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        self : object\u001b[0m\n",
      "\u001b[0;34m            Fitted estimator.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"The number of samples must be more than the number of classes.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# estimate priors from sample\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# non-negative ints\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"priors must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The priors do not sum to 1. Renormalizing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Maximum number of components no matter what n_components is\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# specified:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_components\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_components\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"n_components cannot be larger than min(n_features, n_classes - 1).\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"svd\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shrinkage not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"covariance estimator \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"is not supported \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"with svd solver. Try another solver\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lsqr\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_lsqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"eigen\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_eigen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"unknown solver {} (valid solvers are 'svd', \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"'lsqr', and 'eigen').\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# treat binary case as a special case\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_features_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Project data to maximize class separation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Input data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        X_new : ndarray of shape (n_samples, n_components) or \\\u001b[0m\n",
      "\u001b[0;34m            (n_samples, min(rank, n_components))\u001b[0m\n",
      "\u001b[0;34m            Transformed data. In the case of the 'svd' solver, the shape\u001b[0m\n",
      "\u001b[0;34m            is (n_samples, min(rank, n_components)).\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lsqr\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"transform not implemented for 'lsqr' solver (use 'svd' or 'eigen').\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"svd\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"eigen\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Estimate probability.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Input data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        C : ndarray of shape (n_samples, n_classes)\u001b[0m\n",
      "\u001b[0;34m            Estimated probabilities.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Estimate log probability.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Input data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        C : ndarray of shape (n_samples, n_classes)\u001b[0m\n",
      "\u001b[0;34m            Estimated log probabilities.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiny\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Apply decision function to an array of samples.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        The decision function is equal (up to a constant factor) to the\u001b[0m\n",
      "\u001b[0;34m        log-posterior of the model, i.e. `log p(y = k | x)`. In a binary\u001b[0m\n",
      "\u001b[0;34m        classification setting this instead corresponds to the difference\u001b[0m\n",
      "\u001b[0;34m        `log p(y = 1 | x) - log p(y = 0 | x)`. See :ref:`lda_qda_math`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Array of samples (test vectors).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        C : ndarray of shape (n_samples,) or (n_samples, n_classes)\u001b[0m\n",
      "\u001b[0;34m            Decision function values related to each class, per sample.\u001b[0m\n",
      "\u001b[0;34m            In the two-class case, the shape is (n_samples,), giving the\u001b[0m\n",
      "\u001b[0;34m            log likelihood ratio of the positive class.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Only override for the doc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           /opt/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "LDA??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
