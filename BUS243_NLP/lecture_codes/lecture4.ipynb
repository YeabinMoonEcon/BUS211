{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Thought experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = {}\n",
    "tfidf = dict(list(zip('cat dog apple lion NYC love'.split(), np.random.rand(6)))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `tfidf` vector is just a random example, as if it were computed for a single document that contained these words in some random proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0.30743560800316083,\n",
       " 'dog': 0.5168671642929766,\n",
       " 'apple': 0.5555888696205626,\n",
       " 'lion': 0.07329871754506678,\n",
       " 'NYC': 0.38247893571977465,\n",
       " 'love': 0.7274697256234035}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic['pet'] = (  .3 * tfidf['cat'] \n",
    "                + .3 * tfidf['dog'] \n",
    "                + 0 * tfidf['apple']\n",
    "                + 0 * tfidf['lion'] \n",
    "                - .2 * tfidf['NYC'] \n",
    "                + .2 * tfidf['love'])\n",
    "\n",
    "topic['animal'] = (.1 * tfidf['cat'] \n",
    "                   + .1 * tfidf['dog'] \n",
    "                   - .1 * tfidf['apple']\n",
    "                   + .5 * tfidf['lion'] \n",
    "                   + .1 * tfidf['NYC'] \n",
    "                   - .1 * tfidf['love'])\n",
    "\n",
    "topic['city'] = (0 * tfidf['cat'] \n",
    "                 - .1 * tfidf['dog'] \n",
    "                 + .2 * tfidf['apple']\n",
    "                 - .1 * tfidf['lion'] \n",
    "                 + .5 * tfidf['NYC'] \n",
    "                 + .1 * tfidf['love'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hand-crafted* weights (.3, .3, 0, 0, -.2, .2) are multiplied by imaginary tfidf values to create topic vectors for your imaginary random document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pet': 0.316288989669567,\n",
       " 'animal': 0.029021670049728,\n",
       " 'city': 0.3160876261625359}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{bmatrix}\n",
    ".3 & .3& 0& 0& -.2& .2\\\\\n",
    ".1 &.1 &-.1& .5& .1 &-.1\\\\\n",
    "0 &-.1& .2& -.1& .5 &.1\\\\\n",
    "\\end{bmatrix}$\n",
    "$\\begin{bmatrix}\n",
    "\\text{cat} \\\\ \n",
    "\\text{dog} \\\\ \n",
    "\\text{apple} \\\\ \n",
    "\\text{lion} \\\\ \n",
    "\\text{NYC} \\\\ \n",
    "\\text{love} \\\\ \n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\text{pet}\\\\\n",
    "\\text{animal}\\\\\n",
    "\\text{city}\\\\\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Go back to the slide.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic to word? No problem, but the same problem still there.\n",
    "\n",
    "How to assign the weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0.09778886390584289,\n",
       " 'dog': 0.0661801012895893,\n",
       " 'apple': 0.06031535822753438,\n",
       " 'lion': -0.01709792759138959,\n",
       " 'NYC': 0.09768818215232734,\n",
       " 'love': 0.09196439354519419}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector = {}\n",
    "word_vector['cat'] = .3 * topic['pet'] + .1 * topic['animal'] + 0 * topic['city']\n",
    "word_vector['dog'] = .3 * topic['pet'] + .1 * topic['animal'] - .1 * topic['city']\n",
    "word_vector['apple'] = 0 * topic['pet'] - .1 * topic['animal'] + .2 * topic['city']\n",
    "word_vector['lion'] = 0 * topic['pet'] + .5 * topic['animal'] - .1 * topic['city']\n",
    "word_vector['NYC'] = -.2 * topic['pet'] + .1 * topic['animal'] + .5 * topic['city']\n",
    "word_vector['love'] = .2 * topic['pet'] - .1 * topic['animal'] + .1 * topic['city']\n",
    "word_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 An LDA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nlpia'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnlpia\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloaders\u001b[39;00m \u001b[39mimport\u001b[39;00m get_data\n\u001b[1;32m      3\u001b[0m pd\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mwidth \u001b[39m=\u001b[39m \u001b[39m120\u001b[39m\n\u001b[1;32m      4\u001b[0m sms \u001b[39m=\u001b[39m get_data(\u001b[39m'\u001b[39m\u001b[39msms-spam\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nlpia'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nlpia.data.loaders import get_data\n",
    "pd.options.display.width = 120\n",
    "sms = get_data('sms-spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
