<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>BUS212:lecture2</title>

		<link rel="stylesheet" href="../../dist/reset.css">
		<link rel="stylesheet" href="../../dist/reveal.css">
		<link rel="stylesheet" href="../../dist/theme/white.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="../../plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					<textarea data-template>
						## Advanced Data Analytics
						## Lecture 2 
						### What is a modern data analytics?
						
					</textarea>
				  </section>
				  
				  <section>Read Chapter 1: Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition</section>
				  <section>Let's start with an example</section>
				  
				  <section>
					<ul>
						<li class="fragment">Suppose you are a marketing analyst</li>
						<ul>
							<li class="fragment">investigate the association between advertising and sales of a particular product</li>
							<li class="fragment">data set consists of the sales of that product	in 200 different markets</li>
							
							<li class="fragment">Your client can control the advertising expenditure in each of the three media</li>
							<ul>
								<li class="fragment">advertising budgets: TV, radio, newspaper</li>
							</ul>
						</ul>
						
					</ul>
				</section>

				<section>
					<img src="pics/pic2_1.png" width=800 class=""fragment><br>
					<ul>
						
						<ul>
							<li class="fragment">Advertising budgets are input variables while sales is an output 								variable is an output variable</li>
							
							<ul>
								<li class="fragment">inputs: predictors, independent variables, features $\rightarrow X$ </li>
								<li class="fragment">outputs: response, target, dependent variables$\rightarrow Y$</li>
							</ul>
						</ul>
						
					</ul>
				</section>
				  
				 
				 <section>
					<ul>
						<li class="fragment">Suppose we observe $Y$ and $p$ different predictors, $X_1,X_2,...,X_p$</li>
						
						<li class="fragment">Assume that there is some relationship between $Y$ and $X = (X_1,X2,...,X_p)$, which can be written
							in the very general form: $Y=f(X)+\epsilon$</li>
						
						
						<ul>
							<li class="fragment">$f$ is some fixed but unknown function of $X$, and $\epsilon$ is a random
								error term, which is independent of $X$ and has mean zero</li>	
								<li class="fragment">$f$ represents the systematic information that $X$ provides about $Y$</li>
						</ul>
						
						
					</ul>	
		        </section>
			  <section> 
			  		<ul>
						<li class="fragment">Consider the difference:</li>
						<ul>
							
							<li class="fragment">$\text{Income} =f(\text{education})+\epsilon$</li>
							<li class="fragment">$\text{Income in \$} =f(\text{Income in &euro;})+\epsilon$</li>
						</ul>
					</ul>

				
					
					
					 </section>
					
				
				<section>Why estimate $f$?</section>
				<section>There are two main reasons: prediction and inference</section>
				<section>Let's focus on prediction first</section>
				<section>
					<ul>
						<li class="fragment">In many situations,$X$ are readily available, but $Y$ cannot be easily obtained</li>
						<li class="fragment">Given the error term averages to zero, predict $Y$ using $\hat{Y}=\hat{f}(X)$</li>
						<ul>
							<li class="fragment">$\hat{f}$ represents our estimate for $f$</li>
							<li class="fragment">often treated as a black box</li>
							<ul>
								<li class="fragment">examples?</li>
							</ul>
						</ul>
						
					</ul>
				</section>
				
				<section>Reducible error: how to improve $\hat{f}$</section>
				<section>Irreducible error: $\epsilon$ <br>because no matter how well we estimate $f$, we
					cannot reduce the error introduced by $\epsilon$</section>

				<section>Why is the irreducible error larger than zero?</section>
				<section>The focus of the most data analysis is on techniques for estimating $f$ with the aim of
					minimizing the reducible error</section>


				<section>Now inference</section>
				<section>

					<ul>
						<li class="fragment">We are often interested in understanding the association between $Y$ and $X$</li>
						<li class="fragment">Still, we wish to estimate $f$, but our goal is not necessarily to make predictions for $Y$</li>
						<li class="fragment">Now $\hat{f}$ cannot be treated as a black	box, because we need to know its exact form</li>
						<ul>
							<li class="fragment">Which media are associated with sales?</li>
							<li class="fragment">Which media generate the biggest boost in sales?</li>
							
						</ul>
						
					</ul>
				</section>
		
				<section>Some modeling could be conducted both for prediction and inference</section>
		
				<section>Depending on whether our ultimate goal is prediction, inference, or a
					combination of the two, different methods for estimating $f$ may be appropriate</section>
				<section>Simple model vs. Complex model</section>
				<section>The Trade-Off Between<br> Prediction Accuracy and Model Interpretability</section>
				
				<section>Why would we ever choose to use a more restrictive method instead of a very flexible approach?</section>
				<section>
					<ul>
						<li class="fragment">If we are mainly interested in inference, then restrictive (simple) models are much more interpretable</li>
						<li class="fragment">Still, we wish to estimate $f$, but our goal is not necessarily to make predictions for $Y$</li>
						<ul>
							<li class="fragment">linear model</li>
						</ul>
						<li class="fragment">Flexible model would produce more accurate estimates but difficult to understand</li>
						
					</ul>
				</section>
			<section>In some settings, however, we are only interested in prediction, and
				the interpretability of the predictive model is simply not of interest</section>
				<section>However, we will often obtain more accurate predictions using a less flexible method</section>


				<section>One of the key aims of this class is to introduce a wide range
					of learning methods that extend far beyond the standard linear
					regression approach</section>
				<section>No one method dominates all others over all possible data sets</section>
				<section>Selecting the best approach can be one of the most challenging parts of performing statistical learning in
					practice</section>
					
					<section>
						<h4>Assessing Model Accuracy</h4>
						<ul>
							<li class="fragment">Measuring a quality of fit depends on the model</li>
							<li class="fragment"> In the regression setting, the mean squared error (MSE) </li>
							<ul>
								<li class="fragment">$\text{MSE}=\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{f}(x_i)  )^2$</li>
								<li class="fragment">The MSE will be small if the predicted responses are very close to the true responses</li>
							</ul>
							
							
						</ul>
					</section>

					<section>We are interested in the accuracy of the predictions that we obtain when we apply our method to previously unseen 	data</section>

					<section>
						<ul>
							<li class="fragment">Suppose fit the model using the training obs {$(x_1,y_1),...,(x_n,y_n)$} and obtatin $\hat{f}$</li>
							<li class="fragment">Really not interested in whether $\hat{f}(x_i) \approx y_i$</li>
							<li class="fragment">Instead, $\hat{f}(x_0) \approx y_0$, where $(x_0,y_0)$  is a previously unseen test observation not used to train
								the statistical learning method</li>
							
							<li class="fragment">We want to choose the method that gives	the lowest test MSE, as opposed to the lowest training MSE</li>
							
						</ul>
					</section>
					<section>How can we go about trying to select a method that minimizes the test MSE?</section>
					<section>In some settings, we may have a test data set available, so choose the model having the lowest test MSE</section>
					<section>But what if no test observations are available?</section>	
					<section>How about: select a method<br> that minimizes the training MSE?</section>
					<section> It might be a sensible approach, since the training MSE and the test MSE appear to be closely related</section>
			
					<section>Unfortunately, there
						is no guarantee that<br> the method with the lowest training MSE<br> will also
						have the lowest test MSE</section>
				</div>	

		<script src="../../dist/reveal.js"></script>
		<script src="../../plugin/notes/notes.js"></script>
		<script src="../../plugin/markdown/markdown.js"></script>
		<script src="../../plugin/highlight/highlight.js"></script>
		<script src="../../plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				progress: false,
				touch: true,
				slideNumber: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});
		</script>
	</body>
</html>
